{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“˜ word_full_pipeline_v8.3 â€” Word â†’ CSV â†’ YAML â†’ RST(æ¨¡å—åŒ–) â†’ Sphinx(HTML)\n",
    "\n",
    "æœ¬ç‰ˆæœ¬åœ¨ v8.1 çš„åŸºç¡€ä¸Šï¼Œ**åˆå¹¶ v6.2 çš„å®Œæ•´æŠ½å–é€»è¾‘**ï¼Œå®ç°ï¼š\n",
    "- âœ… ä» Word è‡ªåŠ¨æŠ½å– **å‘½ä»¤æ ‡é¢˜/æè¿°**ã€**å‚æ•°ï¼ˆå«åµŒå¥—è¡¨ valmapï¼‰**ã€**ç¤ºä¾‹ï¼ˆæ®µè½/è¡¨æ ¼ï¼‰**ï¼›\n",
    "- âœ… ç”Ÿæˆ YAMLï¼Œå¹¶è¿›è¡ŒåŸºæœ¬æ ¡éªŒï¼›\n",
    "- âœ… ç”Ÿæˆæ¨¡å—åŒ– RSTï¼ˆå¸¦ `_cmd_...` é”šç‚¹ï¼Œæ”¯æŒåˆ†ç»„ TOCï¼‰ï¼›\n",
    "- âœ… ä¸€é”®åˆå§‹åŒ– Sphinx å¹¶æ„å»º HTMLï¼ˆå« `docutils<0.21` å…¼å®¹ã€Windows ç¼–ç å®‰å…¨ï¼‰ã€‚\n",
    "\n",
    "> ä½¿ç”¨å‰è¯·å°† `AT_Commands.docx` æ”¾åœ¨ä¸æœ¬ Notebook åŒç›®å½•ã€‚\n",
    ">\n",
    "è¿è¡Œé¡ºåºï¼šStep 0 â†’ Step 6ï¼ˆæˆ–ç›´æ¥æ‰§è¡Œ `run_all(clean=True)`ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 â€” å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡è¿è¡Œéœ€è¦ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä¾èµ–å®‰è£…å®Œæˆï¼ˆå« docutils<0.21 å…¼å®¹ï¼‰\n"
     ]
    }
   ],
   "source": [
    "!pip install -q python-docx pandas pyyaml jinja2 sphinx sphinx-book-theme sphinx-copybutton \"docutils<0.21\" lxml\n",
    "print(\"âœ… ä¾èµ–å®‰è£…å®Œæˆï¼ˆå« docutils<0.21 å…¼å®¹ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0.5 â€” é…ç½®ä¸é€šç”¨å·¥å…·ï¼ˆè·¯å¾„ã€æ—¥å¿—ã€ç›®å½•æŸ¥çœ‹ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… é…ç½®å°±ç»ªï¼›è¾“å‡ºç›®å½•ï¼šdata/ã€docs/zh_CN/\n"
     ]
    }
   ],
   "source": [
    "import os, re, json, traceback, datetime, subprocess, sys, shutil\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "from docx import Document\n",
    "from docx.oxml.text.paragraph import CT_P\n",
    "from docx.oxml.table import CT_Tbl\n",
    "\n",
    "# === è·¯å¾„é…ç½® ===\n",
    "IN_WORD = \"AT_Commands.docx\"\n",
    "DATA_DIR = \"data\"\n",
    "CSV_OUT  = os.path.join(DATA_DIR, \"at_extracted_commands.csv\")\n",
    "YAML_OUT = os.path.join(DATA_DIR, \"at_all_commands.yaml\")\n",
    "RST_DIR  = os.path.join(DATA_DIR, \"rst_output\")\n",
    "\n",
    "# ä»¿ ESP-ATï¼šå¤šè¯­è¨€ç›®å½•ï¼ˆæ­¤å¤„ç”¨ zh_CNï¼‰\n",
    "DOCS_ROOT = \"docs\"\n",
    "LANG = \"zh_CN\"\n",
    "SRC_DIR = os.path.join(DOCS_ROOT, LANG, \"source\")\n",
    "BUILD_HTML = os.path.join(DOCS_ROOT, LANG, \"build\", \"html\")\n",
    "LOG_PATH = \"parse_log.txt\"\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "open(LOG_PATH, \"w\", encoding=\"utf-8\").write(\"\")\n",
    "\n",
    "def log(msg: str):\n",
    "    with open(LOG_PATH, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"[{datetime.datetime.now().isoformat(timespec='seconds')}] {msg}\\n\")\n",
    "\n",
    "def print_tree(root_path):\n",
    "    if not os.path.exists(root_path):\n",
    "        print(f\"(ä¸å­˜åœ¨) {root_path}\")\n",
    "        return\n",
    "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "        level = dirpath.replace(root_path, \"\").count(os.sep)\n",
    "        indent = \"  \" * level\n",
    "        print(f\"{indent}{os.path.basename(dirpath)}/\")\n",
    "        subindent = \"  \" * (level + 1)\n",
    "        for f in filenames:\n",
    "            print(f\"{subindent}{f}\")\n",
    "\n",
    "print(\"âœ… é…ç½®å°±ç»ªï¼›è¾“å‡ºç›®å½•ï¼šdata/ã€docs/zh_CN/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 â€” Word â†’ CSVï¼ˆ**å®Œæ•´æŠ½å–**ï¼šå‘½ä»¤/æè¿° + å‚æ•°ï¼ˆåµŒå¥—è¡¨ï¼‰ + ç¤ºä¾‹ï¼‰\n",
    "æ ¸å¿ƒï¼š\n",
    "- é¡ºåºéå†æ®µè½ä¸è¡¨æ ¼ï¼›\n",
    "- è¯†åˆ«å‘½ä»¤æ ‡é¢˜ã€å‚æ•°æ ‡é¢˜ï¼ˆè¿ç»­è¡¨ï¼‰ã€ç¤ºä¾‹æ ‡é¢˜ï¼›\n",
    "- å‚æ•°å€¼ä¼˜å…ˆä»ç¬¬ä¸‰åˆ—åµŒå¥—è¡¨æå–ï¼Œå…¶æ¬¡ä»æ–‡æœ¬æ¨¡ç³ŠåŒ¹é…ï¼›\n",
    "- ç¤ºä¾‹æ”¯æŒâ€œç¤ºä¾‹æ®µè½â€å’Œâ€œç¤ºä¾‹è¡¨æ ¼â€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\txiab\\AppData\\Local\\Temp\\ipykernel_48908\\2016199789.py:67: DeprecationWarning: 'maxsplit' is passed as positional argument\n",
      "  k, v = re.split(r\"[:ï¼š]\", s, 1); k, v = k.strip(), v.strip()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æå– 44 æ¡å‘½ä»¤ â†’ data\\at_extracted_commands.csv\n",
      "ğŸ“ è§£ææ—¥å¿—ï¼šparse_log.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>å‘½ä»¤</th>\n",
       "      <th>å‘½ä»¤æ ‡é¢˜</th>\n",
       "      <th>å‘½ä»¤ç±»å‹</th>\n",
       "      <th>å‘½ä»¤æ ¼å¼</th>\n",
       "      <th>ç¤ºä¾‹å‘½ä»¤</th>\n",
       "      <th>ç¤ºä¾‹å“åº”</th>\n",
       "      <th>åŠŸèƒ½æè¿°</th>\n",
       "      <th>å¤‡æ³¨</th>\n",
       "      <th>å‚æ•°JSON</th>\n",
       "      <th>é¡ºåº</th>\n",
       "      <th>è¡¨æ•°é‡</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATI</td>\n",
       "      <td>è·å–æ¨¡ç»„å‚å•†ä¿¡æ¯</td>\n",
       "      <td>æ‰§è¡Œ;æŸ¥è¯¢;æµ‹è¯•</td>\n",
       "      <td>ATI</td>\n",
       "      <td>ATI\\nNEOWAY\\nN706\\nV001\\nOK</td>\n",
       "      <td>å‚å®¶ä¿¡æ¯\\næ¨¡ç»„å‹å·\\nç‰ˆæœ¬å·</td>\n",
       "      <td>è·å–æ¨¡ç»„å‚å•†ä¿¡æ¯ï¼ŒåŒ…æ‹¬å‚å®¶ã€å‹å·å’Œç‰ˆæœ¬ã€‚\\nå‘½ä»¤æ ¼å¼</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"name\": \"&lt;manufacturer&gt;\", \"desc\": \"æ¨¡ç»„å‚å•†ä¿¡æ¯ã€äº§å“...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT+GMR</td>\n",
       "      <td>æŸ¥è¯¢ç‰ˆæœ¬ä¿¡æ¯</td>\n",
       "      <td>æ‰§è¡Œ;æŸ¥è¯¢;æµ‹è¯•</td>\n",
       "      <td>AT+GMR</td>\n",
       "      <td>AT+GMR\\n+GMR: N706-R004-STD-BZ-003\\nOK</td>\n",
       "      <td>æŸ¥è¯¢è½¯ä»¶ç‰ˆæœ¬</td>\n",
       "      <td>æŸ¥è¯¢è½¯ä»¶ç‰ˆæœ¬ä¿¡æ¯ã€‚\\nå‘½ä»¤æ ¼å¼</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"name\": \"&lt;reversion&gt;\", \"desc\": \"æ¨¡ç»„è½¯ä»¶ç‰ˆæœ¬ä¿¡æ¯\", \"...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       å‘½ä»¤      å‘½ä»¤æ ‡é¢˜      å‘½ä»¤ç±»å‹    å‘½ä»¤æ ¼å¼                                    ç¤ºä¾‹å‘½ä»¤  \\\n",
       "0     ATI  è·å–æ¨¡ç»„å‚å•†ä¿¡æ¯  æ‰§è¡Œ;æŸ¥è¯¢;æµ‹è¯•     ATI             ATI\\nNEOWAY\\nN706\\nV001\\nOK   \n",
       "1  AT+GMR    æŸ¥è¯¢ç‰ˆæœ¬ä¿¡æ¯  æ‰§è¡Œ;æŸ¥è¯¢;æµ‹è¯•  AT+GMR  AT+GMR\\n+GMR: N706-R004-STD-BZ-003\\nOK   \n",
       "\n",
       "              ç¤ºä¾‹å“åº”                        åŠŸèƒ½æè¿°  å¤‡æ³¨  \\\n",
       "0  å‚å®¶ä¿¡æ¯\\næ¨¡ç»„å‹å·\\nç‰ˆæœ¬å·  è·å–æ¨¡ç»„å‚å•†ä¿¡æ¯ï¼ŒåŒ…æ‹¬å‚å®¶ã€å‹å·å’Œç‰ˆæœ¬ã€‚\\nå‘½ä»¤æ ¼å¼ NaN   \n",
       "1           æŸ¥è¯¢è½¯ä»¶ç‰ˆæœ¬             æŸ¥è¯¢è½¯ä»¶ç‰ˆæœ¬ä¿¡æ¯ã€‚\\nå‘½ä»¤æ ¼å¼ NaN   \n",
       "\n",
       "                                              å‚æ•°JSON  é¡ºåº  è¡¨æ•°é‡  \n",
       "0  [{\"name\": \"<manufacturer>\", \"desc\": \"æ¨¡ç»„å‚å•†ä¿¡æ¯ã€äº§å“...   1    1  \n",
       "1  [{\"name\": \"<reversion>\", \"desc\": \"æ¨¡ç»„è½¯ä»¶ç‰ˆæœ¬ä¿¡æ¯\", \"...   2    1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMD_LINE_PAT = re.compile(r'^\\s*(AT[\\+\\w\\-]+(?:[?=][\\w<>,\\s\\-\\+\\.\\:\\(\\)]*)?)\\s*(?::|ï¼š)?\\s*(.*)$', re.I)\n",
    "PARAM_HEADING_PAT = re.compile(r'^\\s*å‚æ•°(è¯´æ˜|è¡¨|ä¿¡æ¯)?\\s*[:ï¼š]?\\s*$', re.I)\n",
    "EXAMPLE_HEADING_PAT = re.compile(r'^\\s*(ç¤ºä¾‹|Examples?)\\s*[:ï¼š]?\\s*$', re.I)\n",
    "\n",
    "def is_cmd_heading(text): return bool(CMD_LINE_PAT.match(text or \"\"))\n",
    "def is_param_heading(text): return bool(PARAM_HEADING_PAT.match(text or \"\"))\n",
    "def is_example_heading(text): return bool(EXAMPLE_HEADING_PAT.match(text or \"\"))\n",
    "\n",
    "def iter_ordered_blocks(doc):\n",
    "    body = doc._element.body\n",
    "    tbl_idx = 0\n",
    "    for child in body.iterchildren():\n",
    "        if isinstance(child, CT_P):\n",
    "            text = \"\".join([t.text for t in child.xpath('.//w:t') if t.text]).strip()\n",
    "            yield (\"p\", text)\n",
    "        elif isinstance(child, CT_Tbl):\n",
    "            table_obj = doc.tables[tbl_idx]\n",
    "            tbl_idx += 1\n",
    "            yield (\"tbl\", table_obj)\n",
    "\n",
    "def cell_plain_text(cell):\n",
    "    return \"\\n\".join([p.text.strip() for p in cell.paragraphs if p.text and p.text.strip()]).strip()\n",
    "\n",
    "def find_nested_tbls_in_cell(cell):\n",
    "    xml_str = cell._tc.xml\n",
    "    root = etree.fromstring(xml_str.encode(\"utf-8\"))\n",
    "    ns = {\"w\": \"http://schemas.openxmlformats.org/wordprocessingml/2006/main\"}\n",
    "    return root.findall(\".//w:tbl\", ns), ns\n",
    "\n",
    "def tbl_rows_as_text(tbl, ns):\n",
    "    rows = []\n",
    "    for r in tbl.findall(\".//w:tr\", ns):\n",
    "        cells = r.findall(\".//w:tc\", ns)\n",
    "        row = [\"\".join(tn.text for tn in c.iterfind(\".//w:t\", ns) if tn.text).strip() for c in cells]\n",
    "        rows.append(row)\n",
    "    return rows\n",
    "\n",
    "def looks_like_header(row):\n",
    "    hdr = \" \".join(row[:3])\n",
    "    return any(k in hdr for k in [\"å‚æ•°\",\"åç§°\",\"Name\",\"æè¿°\",\"è¯´æ˜\",\"å«ä¹‰\",\"å–å€¼\",\"å€¼\",\"value\",\"meaning\",\"å¤‡æ³¨\",\"èŒƒå›´\"])\n",
    "\n",
    "def nested_table_to_valmap(rows):\n",
    "    if not rows: return {}\n",
    "    start = 1 if looks_like_header(rows[0]) else 0\n",
    "    kv = {}\n",
    "    for r in rows[start:]:\n",
    "        if not r: continue\n",
    "        key = (r[0] or \"\").strip()\n",
    "        val = \" | \".join([c for c in r[1:] if c and c.strip()]) if len(r) > 1 else \"\"\n",
    "        if key: kv[key] = val\n",
    "    return kv\n",
    "\n",
    "def cell_valmap_from_nested_table(cell):\n",
    "    tbls, ns = find_nested_tbls_in_cell(cell); mapping = {}\n",
    "    for t in tbls:\n",
    "        rows = tbl_rows_as_text(t, ns); mapping.update(nested_table_to_valmap(rows))\n",
    "    return mapping\n",
    "\n",
    "def parse_enum_map_fuzzy(text):\n",
    "    if not text: return {}\n",
    "    segs = re.split(r\"[,\\uFF0C;\\uFF1B\\n]+\", text.strip())\n",
    "    m = {}\n",
    "    for s in segs:\n",
    "        s = s.strip()\n",
    "        if not s: continue\n",
    "        if \":\" in s or \"ï¼š\" in s:\n",
    "            k, v = re.split(r\"[:ï¼š]\", s, 1); k, v = k.strip(), v.strip()\n",
    "        else:\n",
    "            m2 = re.match(r\"^(\\S+)\\s*(?:->|â†’|=>|-|â€”|\\s)\\s*(.+)$\", s)\n",
    "            if m2: k, v = m2.group(1).strip(), m2.group(2).strip()\n",
    "            else:\n",
    "                m3 = re.match(r\"^([A-Za-z0-9\\+\\-\\.]+)\\s+(.+)$\", s)\n",
    "                if m3: k, v = m3.group(1).strip(), m3.group(2).strip()\n",
    "                else: continue\n",
    "        if k: m[k] = v\n",
    "    return m\n",
    "\n",
    "def extract_examples_from_block(blocks, start_idx):\n",
    "    examples = []\n",
    "    i = start_idx\n",
    "    pending_cmd = None\n",
    "    while i < len(blocks):\n",
    "        t, o = blocks[i]\n",
    "        if t == \"p\" and (is_cmd_heading(o) or is_param_heading(o) or is_example_heading(o)):\n",
    "            if is_example_heading(o):\n",
    "                i += 1\n",
    "                continue\n",
    "            break\n",
    "        if t == \"p\":\n",
    "            line = (o or \"\").strip()\n",
    "            if not line:\n",
    "                i += 1; continue\n",
    "            if line.startswith(\"AT+\"):\n",
    "                if pending_cmd:\n",
    "                    examples.append({\"cmd\": pending_cmd, \"resp\": \"\"})\n",
    "                pending_cmd = line\n",
    "            elif pending_cmd and (line.startswith(\"+\") or line in (\"OK\",\"ERROR\") or line.startswith(\"ERROR\")):\n",
    "                examples.append({\"cmd\": pending_cmd, \"resp\": line}); pending_cmd = None\n",
    "        elif t == \"tbl\":\n",
    "            tbl = o\n",
    "            for r in tbl.rows:\n",
    "                cols = r.cells\n",
    "                if not any(c.text.strip() for c in cols):\n",
    "                    continue\n",
    "                cmd = cell_plain_text(cols[0]) if len(cols) > 0 else \"\"\n",
    "                resp = cell_plain_text(cols[1]) if len(cols) > 1 else \"\"\n",
    "                if cmd:\n",
    "                    examples.append({\"cmd\": cmd, \"resp\": resp})\n",
    "        i += 1\n",
    "    if pending_cmd:\n",
    "        examples.append({\"cmd\": pending_cmd, \"resp\": \"\"})\n",
    "    return examples, i\n",
    "\n",
    "def extract_word_to_csv(docx_path, csv_out):\n",
    "    if not os.path.exists(docx_path):\n",
    "        raise FileNotFoundError(f\"æœªæ‰¾åˆ° Word æ–‡ä»¶: {docx_path}\")\n",
    "    doc = Document(docx_path)\n",
    "    seq = list(iter_ordered_blocks(doc))\n",
    "    rows = []\n",
    "    i = 0; order = 0\n",
    "    while i < len(seq):\n",
    "        t, o = seq[i]\n",
    "        if t == \"p\" and is_cmd_heading(o):\n",
    "            m = CMD_LINE_PAT.match(o)\n",
    "            command = m.group(1).strip()\n",
    "            title = (m.group(2) or \"\").strip()\n",
    "            order += 1\n",
    "\n",
    "            # æè¿°æ±‡æ€»\n",
    "            desc_lines = []\n",
    "            j = i + 1\n",
    "            while j < len(seq):\n",
    "                t2, o2 = seq[j]\n",
    "                if t2 == \"p\" and (is_cmd_heading(o2) or is_param_heading(o2) or is_example_heading(o2)):\n",
    "                    break\n",
    "                if t2 == \"p\" and o2:\n",
    "                    desc_lines.append(o2)\n",
    "                elif t2 == \"tbl\":\n",
    "                    break\n",
    "                j += 1\n",
    "            description = \"\\n\".join(desc_lines).strip()\n",
    "\n",
    "            # å‚æ•°è§£æ\n",
    "            params = []; table_count = 0\n",
    "            k = j\n",
    "            while k < len(seq):\n",
    "                t3, o3 = seq[k]\n",
    "                if t3 == \"p\" and is_cmd_heading(o3):\n",
    "                    break\n",
    "                if t3 == \"p\" and is_param_heading(o3):\n",
    "                    k += 1\n",
    "                    while k < len(seq) and seq[k][0] == \"tbl\":\n",
    "                        table = seq[k][1]; table_count += 1\n",
    "                        for r in table.rows:\n",
    "                            cols = r.cells\n",
    "                            if not any(c.text.strip() for c in cols):\n",
    "                                continue\n",
    "                            name = cell_plain_text(cols[0]) if len(cols) > 0 else \"\"\n",
    "                            desc = cell_plain_text(cols[1]) if len(cols) > 1 else \"\"\n",
    "                            valmap = {}\n",
    "                            if len(cols) > 2:\n",
    "                                valmap = cell_valmap_from_nested_table(cols[2]) or parse_enum_map_fuzzy(cell_plain_text(cols[2]))\n",
    "                            if not valmap and len(cols) > 1:\n",
    "                                valmap = cell_valmap_from_nested_table(cols[1]) or parse_enum_map_fuzzy(desc)\n",
    "                            # è·³è¿‡è¡¨å¤´\n",
    "                            if name in (\"å‚æ•°\",\"å‚æ•°å\",\"Name\") and any(x in desc for x in [\"æè¿°\",\"è¯´æ˜\",\"Description\",\"Meaning\"]):\n",
    "                                continue\n",
    "                            if name or desc or valmap:\n",
    "                                params.append({\"name\": name, \"desc\": desc, \"valmap\": valmap})\n",
    "                        k += 1\n",
    "                    continue\n",
    "                k += 1\n",
    "\n",
    "            # ç¤ºä¾‹è§£æ\n",
    "            examples = []\n",
    "            k2 = j\n",
    "            while k2 < len(seq):\n",
    "                t4, o4 = seq[k2]\n",
    "                if t4 == \"p\" and is_example_heading(o4):\n",
    "                    ex, stop_idx = extract_examples_from_block(seq, k2+1)\n",
    "                    examples.extend(ex); k2 = stop_idx\n",
    "                elif t4 == \"p\" and is_cmd_heading(o4):\n",
    "                    break\n",
    "                else:\n",
    "                    k2 += 1\n",
    "\n",
    "            # å‹å› CSV ç»“æ„\n",
    "            ex_cmd_join = \"|\".join([e[\"cmd\"] for e in examples]) if examples else command\n",
    "            ex_resp_join = \"|\".join([e[\"resp\"] for e in examples]) if examples else \"\"\n",
    "\n",
    "            rows.append({\n",
    "                \"å‘½ä»¤\": command,\n",
    "                \"å‘½ä»¤æ ‡é¢˜\": title,\n",
    "                \"å‘½ä»¤ç±»å‹\": \"æ‰§è¡Œ;æŸ¥è¯¢;æµ‹è¯•\",\n",
    "                \"å‘½ä»¤æ ¼å¼\": command,\n",
    "                \"ç¤ºä¾‹å‘½ä»¤\": ex_cmd_join,\n",
    "                \"ç¤ºä¾‹å“åº”\": ex_resp_join,\n",
    "                \"åŠŸèƒ½æè¿°\": description or title,\n",
    "                \"å¤‡æ³¨\": \"\",\n",
    "                \"å‚æ•°JSON\": json.dumps(params, ensure_ascii=False),\n",
    "                \"é¡ºåº\": order,\n",
    "                \"è¡¨æ•°é‡\": table_count\n",
    "            })\n",
    "            i = max(j, k, k2); continue\n",
    "        i += 1\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(CSV_OUT, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"âœ… æå– {len(df)} æ¡å‘½ä»¤ â†’ {CSV_OUT}\")\n",
    "    print(f\"ğŸ“ è§£ææ—¥å¿—ï¼š{LOG_PATH}\")\n",
    "    df.head(3)\n",
    "\n",
    "_ = extract_word_to_csv(IN_WORD, CSV_OUT)\n",
    "pd.read_csv(CSV_OUT).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 â€” CSV â†’ YAMLï¼ˆåˆå¹¶ç¤ºä¾‹ & å‚æ•° JSONï¼‰+ æ ¡éªŒï¼ˆ2.5ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²ç”Ÿæˆ YAML â†’ data\\at_all_commands.yaml\n",
      "âœ… YAML æ ¡éªŒé€šè¿‡ï¼Œå…± 44 æ¡å‘½ä»¤\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "def csv_to_yaml(csv_path, yaml_path):\n",
    "    df = pd.read_csv(csv_path, dtype=str).fillna(\"\")\n",
    "    objs = []\n",
    "    for _, r in df.iterrows():\n",
    "        params = json.loads(r.get(\"å‚æ•°JSON\",\"[]\")) if r.get(\"å‚æ•°JSON\") else []\n",
    "        # å¤„ç†ç¤ºä¾‹ï¼ˆ'|' ä¸² â†’ åˆ—è¡¨[{cmd, resp}]ï¼‰\n",
    "        cparts = [x.strip() for x in r.get(\"ç¤ºä¾‹å‘½ä»¤\",\"\" ).split(\"|\") if x.strip()]\n",
    "        rparts = [x.strip() for x in r.get(\"ç¤ºä¾‹å“åº”\",\"\" ).split(\"|\")]\n",
    "        examples = []\n",
    "        for idx, c in enumerate(cparts):\n",
    "            resp = rparts[idx] if idx < len(rparts) else \"\"\n",
    "            examples.append({\"cmd\": c, \"resp\": resp})\n",
    "\n",
    "        objs.append({\n",
    "            \"command\": r[\"å‘½ä»¤\"],\n",
    "            \"title\": r[\"å‘½ä»¤æ ‡é¢˜\"],\n",
    "            \"type\": [t.strip() for t in r[\"å‘½ä»¤ç±»å‹\"].split(\";\") if t.strip()],\n",
    "            \"formats\": [f.strip() for f in r[\"å‘½ä»¤æ ¼å¼\"].split(\"|\") if f.strip()] or [r[\"å‘½ä»¤æ ¼å¼\"]],\n",
    "            \"parameters\": params,\n",
    "            \"examples\": examples,\n",
    "            \"description\": r.get(\"åŠŸèƒ½æè¿°\",\"\"),\n",
    "            \"notes\": r.get(\"å¤‡æ³¨\",\"\"),\n",
    "            \"meta\": {\"order\": int(r.get(\"é¡ºåº\",\"0\") or 0), \"tables\": int(r.get(\"è¡¨æ•°é‡\",\"0\") or 0)}\n",
    "        })\n",
    "    objs.sort(key=lambda x: x[\"meta\"][\"order\"])  # ä¿åº\n",
    "    with open(yaml_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        yaml.safe_dump({\"commands\": objs}, f, allow_unicode=True, sort_keys=False)\n",
    "    print(f\"âœ… å·²ç”Ÿæˆ YAML â†’ {yaml_path}\")\n",
    "    return yaml_path\n",
    "\n",
    "csv_to_yaml(CSV_OUT, YAML_OUT)\n",
    "\n",
    "def validate_yaml(yaml_path):\n",
    "    with open(yaml_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = yaml.safe_load(f) or {}\n",
    "    cmds = data.get(\"commands\", [])\n",
    "    seen = set(); err = []\n",
    "    for c in cmds:\n",
    "        cmd = c.get(\"command\",\"\")\n",
    "        if not cmd: err.append(\"ç¼ºå°‘ command\"); continue\n",
    "        if cmd in seen: err.append(f\"é‡å¤ command: {cmd}\")\n",
    "        seen.add(cmd)\n",
    "        for p in c.get(\"parameters\", []):\n",
    "            if not p.get(\"name\") and not p.get(\"desc\") and not p.get(\"valmap\"):  # å…¨ç©ºè§†ä¸ºå™ªå£°\n",
    "                err.append(f\"{cmd}: å­˜åœ¨ç©ºå‚æ•°è¡Œ\")\n",
    "    if err:\n",
    "        print(\"âŒ YAML æ ¡éªŒå¤±è´¥ï¼š\\n - \" + \"\\n - \".join(err))\n",
    "        raise SystemExit(1)\n",
    "    print(f\"âœ… YAML æ ¡éªŒé€šè¿‡ï¼Œå…± {len(cmds)} æ¡å‘½ä»¤\")\n",
    "\n",
    "validate_yaml(YAML_OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 â€” YAML â†’ æ¨¡å—åŒ– RSTï¼ˆå¸¦é”šç‚¹ + å‚æ•°åµŒå¥— valmap + åˆ†ç»„ TOCï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ¨¡å—åŒ– RST å·²ç”Ÿæˆ â†’ data\\rst_output\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AT-CC',\n",
       " 'AT-CE',\n",
       " 'AT-CF',\n",
       " 'AT-CG',\n",
       " 'AT-CI',\n",
       " 'AT-CL',\n",
       " 'AT-CM',\n",
       " 'AT-CN',\n",
       " 'AT-CO',\n",
       " 'AT-CP']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jinja2 import Template\n",
    "from collections import defaultdict\n",
    "\n",
    "def safe_stub(name: str) -> str:\n",
    "    return name.replace(\"+\",\"plus\").replace(\"?\",\"q\").replace(\"=\",\"eq\").replace(\"/\",\"sl\")\n",
    "\n",
    "PAGE_TMPL = Template('''\n",
    ".. _cmd_{{ safe(cmd.command) }}:\n",
    "\n",
    "{{ cmd.command }}\n",
    "{{ '=' * cmd.command|length }}\n",
    "\n",
    "**åŠŸèƒ½è¯´æ˜**\n",
    "{{ cmd.description or cmd.title or '' }}\n",
    "\n",
    "**å‘½ä»¤è¯­æ³•**\n",
    "::\n",
    "{% for f in cmd.formats %}\n",
    "   {{ f }}\n",
    "{% endfor %}\n",
    "\n",
    "**å‚æ•°è¯´æ˜**\n",
    "\n",
    ".. list-table::\n",
    "   :header-rows: 1\n",
    "   :widths: 18 32 50\n",
    "   :class: cmd-param-table\n",
    "\n",
    "   * - å‚æ•°å\n",
    "     - æè¿°\n",
    "     - å–å€¼\n",
    "{% for p in cmd.parameters %}\n",
    "   * - {{ p.name or 'â€”' }}\n",
    "     - {{ p.desc or 'â€”' }}\n",
    "     - {% if p.valmap %}\n",
    "       .. list-table::\n",
    "          :header-rows: 1\n",
    "          :widths: 25 75\n",
    "\n",
    "          * - å€¼\n",
    "            - å«ä¹‰\n",
    "{% for k, v in p.valmap.items() %}\n",
    "          * - {{ k }}\n",
    "            - {{ v }}\n",
    "{% endfor %}\n",
    "       {% else %} N/A {% endif %}\n",
    "{% endfor %}\n",
    "\n",
    "**ç¤ºä¾‹**\n",
    ".. code-block:: bash\n",
    "\n",
    "{% for ex in cmd.examples %}\n",
    "   {{ ex.cmd }}\n",
    "{% if ex.resp %}\n",
    "   {{ ex.resp }}\n",
    "{% endif %}\n",
    "{% if loop.nextitem %}\n",
    "   # â€”â€” ä»¥ä¸‹ç¤ºä¾‹ â€”â€”\n",
    "{% endif %}\n",
    "{% endfor %}\n",
    "''')\n",
    "\n",
    "def group_key(cmd_str):\n",
    "    m = re.match(r'^AT\\+([A-Z]+)', (cmd_str or \"\").upper())\n",
    "    if not m: return \"AT-OTHER\"\n",
    "    token = m.group(1)\n",
    "    return f\"AT-{token[:2]}\" if len(token) >= 2 else \"AT-OTHER\"\n",
    "\n",
    "def yaml_to_rst_modular(yaml_path, rst_root):\n",
    "    if os.path.exists(rst_root):\n",
    "        shutil.rmtree(rst_root)\n",
    "    os.makedirs(rst_root, exist_ok=True)\n",
    "    with open(yaml_path, 'r', encoding='utf-8') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    cmds = data.get('commands', [])\n",
    "\n",
    "    groups = defaultdict(list)\n",
    "    for c in cmds:\n",
    "        rst = PAGE_TMPL.render(cmd=c, safe=safe_stub)\n",
    "        fname = f\"{safe_stub(c['command'])}.rst\"\n",
    "        with open(os.path.join(rst_root, fname), 'w', encoding='utf-8') as fo:\n",
    "            fo.write(rst)\n",
    "        groups[group_key(c['command'])].append(fname[:-4])\n",
    "\n",
    "    # åˆ†ç»„ç´¢å¼• + æ€»ç´¢å¼•\n",
    "    for g, items in groups.items():\n",
    "        grp_dir = os.path.join(rst_root, g)\n",
    "        os.makedirs(grp_dir, exist_ok=True)\n",
    "        glines = [g, '=' * len(g), '', \".. toctree::\", \"   :maxdepth: 1\", '']\n",
    "        for it in items:\n",
    "            glines.append(f\"   ../{it}\")\n",
    "        with open(os.path.join(grp_dir, 'index.rst'), 'w', encoding='utf-8') as fo:\n",
    "            fo.write('\\n'.join(glines))\n",
    "\n",
    "    idx = [\"AT å‘½ä»¤æ‰‹å†Œ\", \"==========\", '', \".. toctree::\", \"   :maxdepth: 2\", '']\n",
    "    for g in sorted(groups.keys()):\n",
    "        idx.append(f\"   {g}/index\")\n",
    "    with open(os.path.join(rst_root, 'index.rst'), 'w', encoding='utf-8') as fo:\n",
    "        fo.write('\\n'.join(idx))\n",
    "    print(f\"âœ… æ¨¡å—åŒ– RST å·²ç”Ÿæˆ â†’ {rst_root}\")\n",
    "\n",
    "yaml_to_rst_modular(YAML_OUT, RST_DIR)\n",
    "sorted(os.listdir(RST_DIR))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 â€” åˆå§‹åŒ– Sphinxï¼ˆå¤šè¯­è¨€ç»“æ„ + å®Œæ•´ conf.py + CSSï¼‰\n",
    "è‡ªåŠ¨åˆ›å»º `docs/zh_CN/source/` ç»“æ„ï¼Œå¤åˆ¶ RSTï¼Œå¹¶å†™å…¥ä¸»é¢˜/æ‰©å±•/CSS é…ç½®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ æ£€æµ‹åˆ°æ—§ docs/ï¼Œæ­£åœ¨æ¸…ç†â€¦\n",
      "âœ… å·²åˆ é™¤æ—§ docs/\n",
      "âœ… Sphinx åˆå§‹åŒ–å®Œæˆå¹¶å¤åˆ¶ RST + æ³¨å…¥ä¸»é¢˜ä¸ CSS\n",
      "docs/\n",
      "  zh_CN/\n",
      "    build/\n",
      "      html/\n",
      "    source/\n",
      "      ATD.rst\n",
      "      ATE1.rst\n",
      "      ATI.rst\n",
      "      ATplusCCID.rst\n",
      "      ATplusCCLK.rst\n",
      "      ATplusCEREG.rst\n",
      "      ATplusCESQ.rst\n",
      "      ATplusCFUN.rst\n",
      "      ATplusCGATT.rst\n",
      "      ATplusCGDCONT.rst\n",
      "      ATplusCGMM.rst\n",
      "      ATplusCGSN.rst\n",
      "      ATplusCIMI.rst\n",
      "      ATplusCLCK.rst\n",
      "      ATplusCMGD.rst\n",
      "      ATplusCMGF.rst\n",
      "      ATplusCMGL.rst\n",
      "      ATplusCMGR.rst\n",
      "      ATplusCMGS.rst\n",
      "      ATplusCMGW.rst\n",
      "      ATplusCMSS.rst\n",
      "      ATplusCMUX.rst\n",
      "      ATplusCNMI.rst\n",
      "      ATplusCOPS.rst\n",
      "      ATplusCPIN.rst\n",
      "      ATplusCPMS.rst\n",
      "      ATplusCPWD.rst\n",
      "      ATplusCREG.rst\n",
      "      ATplusCSCA.rst\n",
      "      ATplusCSCS.rst\n",
      "      ATplusCSDH.rst\n",
      "      ATplusCSMP.rst\n",
      "      ATplusCSMS.rst\n",
      "      ATplusCSQ.rst\n",
      "      ATplusGMM.rst\n",
      "      ATplusGMR.rst\n",
      "      ATplusGSN.rst\n",
      "      ATplusIPR.rst\n",
      "      ATplusNSTGETRSSI.rst\n",
      "      ATplusNWDNS.rst\n",
      "      ATplusNWENPWRSAVE.rst\n",
      "      ATplusNWPWROFF.rst\n",
      "      ATplusNWRFTEST.rst\n",
      "      ATplusXGAUTH.rst\n",
      "      conf.py\n",
      "      index.rst\n",
      "      AT-CC/\n",
      "        index.rst\n",
      "      AT-CE/\n",
      "        index.rst\n",
      "      AT-CF/\n",
      "        index.rst\n",
      "      AT-CG/\n",
      "        index.rst\n",
      "      AT-CI/\n",
      "        index.rst\n",
      "      AT-CL/\n",
      "        index.rst\n",
      "      AT-CM/\n",
      "        index.rst\n",
      "      AT-CN/\n",
      "        index.rst\n",
      "      AT-CO/\n",
      "        index.rst\n",
      "      AT-CP/\n",
      "        index.rst\n",
      "      AT-CR/\n",
      "        index.rst\n",
      "      AT-CS/\n",
      "        index.rst\n",
      "      AT-GM/\n",
      "        index.rst\n",
      "      AT-GS/\n",
      "        index.rst\n",
      "      AT-IP/\n",
      "        index.rst\n",
      "      AT-NS/\n",
      "        index.rst\n",
      "      AT-NW/\n",
      "        index.rst\n",
      "      AT-OTHER/\n",
      "        index.rst\n",
      "      AT-XG/\n",
      "        index.rst\n",
      "      _static/\n",
      "        custom.css\n"
     ]
    }
   ],
   "source": [
    "# æ¸…ç†æ—§æ–‡æ¡£\n",
    "if os.path.exists(DOCS_ROOT):\n",
    "    print(\"âš ï¸ æ£€æµ‹åˆ°æ—§ docs/ï¼Œæ­£åœ¨æ¸…ç†â€¦\")\n",
    "    shutil.rmtree(DOCS_ROOT)\n",
    "    print(\"âœ… å·²åˆ é™¤æ—§ docs/\")\n",
    "\n",
    "os.makedirs(SRC_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(SRC_DIR, '_static'), exist_ok=True)\n",
    "os.makedirs(os.path.join(DOCS_ROOT, LANG, 'build', 'html'), exist_ok=True)\n",
    "\n",
    "# å¤åˆ¶ RST\n",
    "shutil.copytree(RST_DIR, SRC_DIR, dirs_exist_ok=True)\n",
    "\n",
    "# å†™ conf.pyï¼ˆå®Œæ•´ï¼‰\n",
    "conf_text = '''\n",
    "project = 'AT Command Manual'\n",
    "master_doc = 'index'\n",
    "language = 'zh_CN'\n",
    "extensions = [\n",
    "    'sphinx.ext.autosectionlabel',\n",
    "    'sphinx_copybutton',\n",
    "]\n",
    "autosectionlabel_prefix_document = True\n",
    "html_theme = 'sphinx_book_theme'\n",
    "html_static_path = ['_static']\n",
    "def setup(app):\n",
    "    app.add_css_file('custom.css')\n",
    "'''\n",
    "with open(os.path.join(SRC_DIR, 'conf.py'), 'w', encoding='utf-8') as f:\n",
    "    f.write(conf_text)\n",
    "\n",
    "# å†™ custom.css\n",
    "custom_css = '''\n",
    "/* æç¤ºå—ä¸è¡¨æ ¼æ ·å¼ */\n",
    ".cmd-param-table th { background: #f2f2f2; }\n",
    ".cmd-param-table td, .cmd-param-table th { padding: 6px 10px; }\n",
    "pre { background: #f8f9fa; border-radius: 6px; padding: 8px; }\n",
    "'''\n",
    "with open(os.path.join(SRC_DIR, '_static', 'custom.css'), 'w', encoding='utf-8') as f:\n",
    "    f.write(custom_css)\n",
    "\n",
    "print(\"âœ… Sphinx åˆå§‹åŒ–å®Œæˆå¹¶å¤åˆ¶ RST + æ³¨å…¥ä¸»é¢˜ä¸ CSS\")\n",
    "print_tree(DOCS_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 â€” æ„å»º HTMLï¼ˆUTF-8 æ—¥å¿— & å¤±è´¥è‡ªåŠ¨å›é€€ docutils å·²åœ¨ Step 0 å¤„ç†ï¼‰\n",
    "Windows å¯èƒ½å‡ºç°æ§åˆ¶å°ç¼–ç é—®é¢˜ï¼Œè¿™é‡Œç”¨ `encoding='utf-8', errors='ignore'` é¿å…ä¹±ç ä¸­æ–­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ å¼€å§‹æ„å»º HTML â€¦\n",
      "\u001b[01mRunning Sphinx v8.2.3\u001b[39;49;00m\n",
      "\u001b[01mloading translations [zh_CN]... \u001b[39;49;00mdone\n",
      "\u001b[01mbuilding [mo]: \u001b[39;49;00mtargets for 0 po files that are out of date\n",
      "\u001b[01mwriting output... \u001b[39;49;00m\n",
      "\u001b[01mbuilding [html]: \u001b[39;49;00mtargets for 64 source files that are out of date\n",
      "\u001b[01mupdating environment: \u001b[39;49;00m[new config] 64 added, 0 changed, 0 removed\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[  2%] \u001b[35mAT-CC/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[  3%] \u001b[35mAT-CE/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[  5%] \u001b[35mAT-CF/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[  6%] \u001b[35mAT-CG/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[  8%] \u001b[35mAT-CI/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[  9%] \u001b[35mAT-CL/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 11%] \u001b[35mAT-CM/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 12%] \u001b[35mAT-CN/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 14%] \u001b[35mAT-CO/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 16%] \u001b[35mAT-CP/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 17%] \u001b[35mAT-CR/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 19%] \u001b[35mAT-CS/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 20%] \u001b[35mAT-GM/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 22%] \u001b[35mAT-GS/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 23%] \u001b[35mAT-IP/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 25%] \u001b[35mAT-NS/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 27%] \u001b[35mAT-NW/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 28%] \u001b[35mAT-OTHER/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 30%] \u001b[35mAT-XG/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 31%] \u001b[35mATD\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 33%] \u001b[35mATE1\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 34%] \u001b[35mATI\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 36%] \u001b[35mATplusCCID\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 38%] \u001b[35mATplusCCLK\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 39%] \u001b[35mATplusCEREG\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 41%] \u001b[35mATplusCESQ\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 42%] \u001b[35mATplusCFUN\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 44%] \u001b[35mATplusCGATT\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 45%] \u001b[35mATplusCGDCONT\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 47%] \u001b[35mATplusCGMM\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 48%] \u001b[35mATplusCGSN\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 50%] \u001b[35mATplusCIMI\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 52%] \u001b[35mATplusCLCK\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 53%] \u001b[35mATplusCMGD\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 55%] \u001b[35mATplusCMGF\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 56%] \u001b[35mATplusCMGL\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 58%] \u001b[35mATplusCMGR\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 59%] \u001b[35mATplusCMGS\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 61%] \u001b[35mATplusCMGW\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 62%] \u001b[35mATplusCMSS\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 64%] \u001b[35mATplusCMUX\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 66%] \u001b[35mATplusCNMI\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 67%] \u001b[35mATplusCOPS\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 69%] \u001b[35mATplusCPIN\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 70%] \u001b[35mATplusCPMS\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 72%] \u001b[35mATplusCPWD\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 73%] \u001b[35mATplusCREG\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 75%] \u001b[35mATplusCSCA\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 77%] \u001b[35mATplusCSCS\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 78%] \u001b[35mATplusCSDH\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 80%] \u001b[35mATplusCSMP\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 81%] \u001b[35mATplusCSMS\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 83%] \u001b[35mATplusCSQ\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 84%] \u001b[35mATplusGMM\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 86%] \u001b[35mATplusGMR\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 88%] \u001b[35mATplusGSN\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 89%] \u001b[35mATplusIPR\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 91%] \u001b[35mATplusNSTGETRSSI\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 92%] \u001b[35mATplusNWDNS\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 94%] \u001b[35mATplusNWENPWRSAVE\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 95%] \u001b[35mATplusNWPWROFF\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 97%] \u001b[35mATplusNWRFTEST\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[ 98%] \u001b[35mATplusXGAUTH\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[100%] \u001b[35mindex\u001b[39;49;00m\n",
      "\n",
      "\u001b[01mlooking for now-outdated files... \u001b[39;49;00mnone found\n",
      "\u001b[01mpickling environment... \u001b[39;49;00mdone\n",
      "\u001b[01mchecking consistency... \u001b[39;49;00mdone\n",
      "\u001b[01mpreparing documents... \u001b[39;49;00mdone\n",
      "\u001b[01mcopying assets... \u001b[39;49;00m\n",
      "\u001b[01mcopying static files... \u001b[39;49;00m\n",
      "Writing evaluated template result to C:\\Users\\txiab\\Documents\\Git-folder\\Building-docs\\docs-as-code-learning\\pipeline-1009\\docs\\zh_CN\\build\\html\\_static\\basic.css\n",
      "Writing evaluated template result to C:\\Users\\txiab\\Documents\\Git-folder\\Building-docs\\docs-as-code-learning\\pipeline-1009\\docs\\zh_CN\\build\\html\\_static\\documentation_options.js\n",
      "Writing evaluated template result to C:\\Users\\txiab\\Documents\\Git-folder\\Building-docs\\docs-as-code-learning\\pipeline-1009\\docs\\zh_CN\\build\\html\\_static\\language_data.js\n",
      "Writing evaluated template result to C:\\Users\\txiab\\Documents\\Git-folder\\Building-docs\\docs-as-code-learning\\pipeline-1009\\docs\\zh_CN\\build\\html\\_static\\copybutton.js\n",
      "\u001b[01mcopying static files: \u001b[39;49;00mdone\n",
      "\u001b[01mcopying extra files... \u001b[39;49;00m\n",
      "\u001b[01mcopying extra files: \u001b[39;49;00mdone\n",
      "\u001b[01mcopying assets: \u001b[39;49;00mdone\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[  2%] \u001b[32mAT-CC/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[  3%] \u001b[32mAT-CE/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[  5%] \u001b[32mAT-CF/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[  6%] \u001b[32mAT-CG/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[  8%] \u001b[32mAT-CI/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[  9%] \u001b[32mAT-CL/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 11%] \u001b[32mAT-CM/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 12%] \u001b[32mAT-CN/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 14%] \u001b[32mAT-CO/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 16%] \u001b[32mAT-CP/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 17%] \u001b[32mAT-CR/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 19%] \u001b[32mAT-CS/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 20%] \u001b[32mAT-GM/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 22%] \u001b[32mAT-GS/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 23%] \u001b[32mAT-IP/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 25%] \u001b[32mAT-NS/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 27%] \u001b[32mAT-NW/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 28%] \u001b[32mAT-OTHER/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 30%] \u001b[32mAT-XG/index\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 31%] \u001b[32mATD\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 33%] \u001b[32mATE1\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 34%] \u001b[32mATI\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 36%] \u001b[32mATplusCCID\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 38%] \u001b[32mATplusCCLK\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 39%] \u001b[32mATplusCEREG\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 41%] \u001b[32mATplusCESQ\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 42%] \u001b[32mATplusCFUN\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 44%] \u001b[32mATplusCGATT\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 45%] \u001b[32mATplusCGDCONT\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 47%] \u001b[32mATplusCGMM\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 48%] \u001b[32mATplusCGSN\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 50%] \u001b[32mATplusCIMI\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 52%] \u001b[32mATplusCLCK\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 53%] \u001b[32mATplusCMGD\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 55%] \u001b[32mATplusCMGF\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 56%] \u001b[32mATplusCMGL\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 58%] \u001b[32mATplusCMGR\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 59%] \u001b[32mATplusCMGS\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 61%] \u001b[32mATplusCMGW\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 62%] \u001b[32mATplusCMSS\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 64%] \u001b[32mATplusCMUX\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 66%] \u001b[32mATplusCNMI\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 67%] \u001b[32mATplusCOPS\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 69%] \u001b[32mATplusCPIN\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 70%] \u001b[32mATplusCPMS\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 72%] \u001b[32mATplusCPWD\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 73%] \u001b[32mATplusCREG\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 75%] \u001b[32mATplusCSCA\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 77%] \u001b[32mATplusCSCS\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 78%] \u001b[32mATplusCSDH\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 80%] \u001b[32mATplusCSMP\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 81%] \u001b[32mATplusCSMS\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 83%] \u001b[32mATplusCSQ\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 84%] \u001b[32mATplusGMM\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 86%] \u001b[32mATplusGMR\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 88%] \u001b[32mATplusGSN\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 89%] \u001b[32mATplusIPR\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 91%] \u001b[32mATplusNSTGETRSSI\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 92%] \u001b[32mATplusNWDNS\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 94%] \u001b[32mATplusNWENPWRSAVE\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 95%] \u001b[32mATplusNWPWROFF\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 97%] \u001b[32mATplusNWRFTEST\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[ 98%] \u001b[32mATplusXGAUTH\u001b[39;49;00m\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[100%] \u001b[32mindex\u001b[39;49;00m\n",
      "\n",
      "\u001b[01mgenerating indices... \u001b[39;49;00mgenindex done\n",
      "\u001b[01mwriting additional pages... \u001b[39;49;00msearch done\n",
      "\u001b[01mdumping search index in Chinese (code: zh)... \u001b[39;49;00mdone\n",
      "\u001b[01mdumping object inventory... \u001b[39;49;00mdone\n",
      "\u001b[01mbuild succeeded, 278 warnings.\u001b[39;49;00m\n",
      "\n",
      "The HTML pages are in docs\\zh_CN\\build\\html.\n",
      "\n",
      "âœ… æ„å»ºæˆåŠŸï¼šdocs\\zh_CN\\build\\html\\index.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_html_fixed():\n",
    "    print(\"ğŸ“¦ å¼€å§‹æ„å»º HTML â€¦\")\n",
    "    # ä¿è¯ index.rst å­˜åœ¨\n",
    "    if not os.path.exists(os.path.join(SRC_DIR, 'index.rst')):\n",
    "        with open(os.path.join(SRC_DIR, 'index.rst'), 'w', encoding='utf-8') as f:\n",
    "            f.write(\"AT Manual\\n=========\\n\\n.. toctree::\\n   :maxdepth: 1\\n\\n\")\n",
    "            for fn in os.listdir(SRC_DIR):\n",
    "                if fn.endswith('.rst') and fn != 'index.rst':\n",
    "                    f.write(f\"   {fn}\\n\")\n",
    "\n",
    "    os.makedirs(BUILD_HTML, exist_ok=True)\n",
    "    cmd = [sys.executable, '-m', 'sphinx', '-b', 'html', SRC_DIR, BUILD_HTML]\n",
    "    p = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore')\n",
    "    print(p.stdout or p.stderr)\n",
    "    index_path = os.path.join(BUILD_HTML, 'index.html')\n",
    "    if os.path.exists(index_path):\n",
    "        print(f\"âœ… æ„å»ºæˆåŠŸï¼š{index_path}\")\n",
    "        return True\n",
    "    print(\"âŒ æ„å»ºå¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—ã€‚\")\n",
    "    return False\n",
    "\n",
    "build_html_fixed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŸ¢ Step 6 â€” ä¸€é”®æ‰§è¡Œ `run_all(clean=True)`ï¼ˆå…¨æµç¨‹è‡ªåŠ¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‡†å¤‡å°±ç»ªã€‚æŒ‰é¡ºåºè¿è¡Œ Step 0â†’6ï¼Œæˆ–ç›´æ¥ run_all(clean=True)ã€‚\n"
     ]
    }
   ],
   "source": [
    "def run_all(clean=True):\n",
    "    if clean and os.path.exists(DOCS_ROOT):\n",
    "        print(\"âš ï¸ run_all: æ¸…ç†æ—§ docs/ â€¦\")\n",
    "        shutil.rmtree(DOCS_ROOT)\n",
    "    _ = extract_word_to_csv(IN_WORD, CSV_OUT)\n",
    "    csv_to_yaml(CSV_OUT, YAML_OUT)\n",
    "    validate_yaml(YAML_OUT)\n",
    "    yaml_to_rst_modular(YAML_OUT, RST_DIR)\n",
    "    # åˆå§‹åŒ– Sphinx\n",
    "    os.makedirs(SRC_DIR, exist_ok=True)\n",
    "    os.makedirs(os.path.join(SRC_DIR, '_static'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(DOCS_ROOT, LANG, 'build', 'html'), exist_ok=True)\n",
    "    shutil.copytree(RST_DIR, SRC_DIR, dirs_exist_ok=True)\n",
    "    # å†™é…ç½®\n",
    "    with open(os.path.join(SRC_DIR, 'conf.py'), 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\"\"project='AT Command Manual'\\nmaster_doc='index'\\nlanguage='zh_CN'\\nextensions=['sphinx.ext.autosectionlabel','sphinx_copybutton']\\nautosectionlabel_prefix_document=True\\nhtml_theme='sphinx_book_theme'\\nhtml_static_path=['_static']\\n\\ndef setup(app):\\n    app.add_css_file('custom.css')\\n\"\"\")\n",
    "    with open(os.path.join(SRC_DIR, '_static', 'custom.css'), 'w', encoding='utf-8') as f:\n",
    "        f.write(\".cmd-param-table th{background:#f2f2f2;} .cmd-param-table td,.cmd-param-table th{padding:6px 10px;} pre{background:#f8f9fa;border-radius:6px;padding:8px;}\")\n",
    "    ok = build_html_fixed()\n",
    "    if ok:\n",
    "        print(\"\\nâœ… å…¨æµç¨‹å®Œæˆã€‚HTML æŸ¥çœ‹ï¼š\", os.path.join(BUILD_HTML, 'index.html'))\n",
    "        print(\"ğŸ“ è§£ææ—¥å¿—ï¼š\", LOG_PATH)\n",
    "    else:\n",
    "        print(\"âŒ æ„å»ºæœªæˆåŠŸï¼Œè¯·å…ˆå•æ­¥æ£€æŸ¥ Step 1~3 çš„è¾“å‡ºã€‚\")\n",
    "\n",
    "print(\"å‡†å¤‡å°±ç»ªã€‚æŒ‰é¡ºåºè¿è¡Œ Step 0â†’6ï¼Œæˆ–ç›´æ¥ run_all(clean=True)ã€‚\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
