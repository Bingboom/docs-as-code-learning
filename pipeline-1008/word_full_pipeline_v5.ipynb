{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82659a24",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸ“˜ Word â†’ CSV â†’ YAML â†’ RST â†’ Sphinx å…¨è‡ªåŠ¨æµæ°´çº¿ v5\n",
    "**ä¸»è¦æ”¹è¿›ï¼š**\n",
    "- æ”¯æŒ Word åµŒå¥—è¡¨æ ¼è§£æï¼Œç”Ÿæˆ `valmap`\n",
    "- CSV / YAML ä¿ç•™å®Œæ•´å‚æ•°æ˜ å°„ç»“æ„\n",
    "- RST æ¸²æŸ“ä½¿ç”¨ `p.valmap` æ¨¡æ¿\n",
    "- å…¼å®¹å¤šè¡Œã€å†’å·ã€ç©ºæ ¼ç­‰å¤æ‚å–å€¼è¡¨è¾¾\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe648e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 0 â€” å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰\n",
    "!pip install -q python-docx pandas pyyaml jinja2 sphinx sphinx_rtd_theme lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb10fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1 â€” Word â†’ CSVï¼ˆè§£æåµŒå¥—è¡¨æ ¼ â†’ valmapï¼‰\n",
    "import os, re, json\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.oxml.text.paragraph import CT_P\n",
    "from docx.oxml.table import CT_Tbl\n",
    "from lxml import etree\n",
    "\n",
    "IN_WORD = \"at-parameter-demo.docx\"\n",
    "CSV_DIR = \"data\"\n",
    "CSV_OUT = os.path.join(CSV_DIR, \"extracted_commands.csv\")\n",
    "os.makedirs(CSV_DIR, exist_ok=True)\n",
    "\n",
    "PARAM_HEADING_PAT = re.compile(r'^\\s*å‚æ•°(è¯´æ˜|è¡¨)?\\s*[:ï¼š]?\\s*$', re.I)\n",
    "CMD_LINE_PAT = re.compile(r'^\\s*(AT\\S*?)\\s*[:ï¼š]\\s*(.*)$')\n",
    "\n",
    "def is_param_heading(text): return bool(PARAM_HEADING_PAT.match(text or \"\"))\n",
    "def is_cmd_heading(text): return bool(CMD_LINE_PAT.match(text or \"\"))\n",
    "\n",
    "def iter_ordered_blocks(doc):\n",
    "    body = doc._element.body; tbl_idx = 0\n",
    "    for child in body.iterchildren():\n",
    "        if isinstance(child, CT_P):\n",
    "            text = ''.join([t.text for t in child.xpath('.//w:t') if t.text]).strip()\n",
    "            yield ('p', text)\n",
    "        elif isinstance(child, CT_Tbl):\n",
    "            table_obj = doc.tables[tbl_idx]; tbl_idx += 1; yield ('tbl', table_obj)\n",
    "\n",
    "def cell_plain_text(cell):\n",
    "    parts = [p.text.strip() for p in cell.paragraphs if p.text and p.text.strip()]\n",
    "    return '\\n'.join(parts).strip()\n",
    "\n",
    "def find_nested_tbls_in_cell(cell):\n",
    "    xml_str = cell._tc.xml\n",
    "    root = etree.fromstring(xml_str.encode('utf-8'))\n",
    "    ns = {\"w\": \"http://schemas.openxmlformats.org/wordprocessingml/2006/main\"}\n",
    "    return root.findall('.//w:tbl', ns), ns\n",
    "\n",
    "def tbl_rows_as_text(tbl, ns):\n",
    "    rows = []\n",
    "    for r in tbl.findall('.//w:tr', ns):\n",
    "        cells = r.findall('.//w:tc', ns)\n",
    "        row = [''.join(tn.text for tn in c.iterfind('.//w:t', ns) if tn.text).strip() for c in cells]\n",
    "        rows.append(row)\n",
    "    return rows\n",
    "\n",
    "def looks_like_header(row):\n",
    "    hdr = ' '.join(row[:3])\n",
    "    return any(k in hdr for k in ['å‚æ•°','åç§°','Name','æè¿°','è¯´æ˜','å–å€¼','å€¼','value','meaning'])\n",
    "\n",
    "def nested_table_to_valmap(rows):\n",
    "    if not rows: return {}\n",
    "    start = 1 if looks_like_header(rows[0]) else 0\n",
    "    kv = {}\n",
    "    for r in rows[start:]:\n",
    "        if not r: continue\n",
    "        key = (r[0] or '').strip()\n",
    "        val = ' | '.join([c for c in r[1:] if c and c.strip()]) if len(r)>1 else ''\n",
    "        if key: kv[key] = val\n",
    "    return kv\n",
    "\n",
    "def cell_valmap_from_nested_table(cell):\n",
    "    tbls, ns = find_nested_tbls_in_cell(cell)\n",
    "    mapping = {}\n",
    "    for t in tbls:\n",
    "        rows = tbl_rows_as_text(t, ns)\n",
    "        mapping.update(nested_table_to_valmap(rows))\n",
    "    return mapping\n",
    "\n",
    "def parse_enum_map_fuzzy(text):\n",
    "    if not text: return {}\n",
    "    segs = re.split(r'[ï¼Œ,;ï¼›\\n]+', text.strip())\n",
    "    m = {}\n",
    "    for s in segs:\n",
    "        s = s.strip()\n",
    "        if not s: continue\n",
    "        if ':' in s or 'ï¼š' in s:\n",
    "            k,v = re.split(r'[:ï¼š]',s,1); k,v=k.strip(),v.strip()\n",
    "        else:\n",
    "            m2 = re.match(r'^(\\S+)\\s*(?:->|â†’|=>|-|â€”|\\s)\\s*(.+)$', s)\n",
    "            if m2: k,v=m2.group(1).strip(),m2.group(2).strip()\n",
    "            else:\n",
    "                m3 = re.match(r'^([A-Za-z0-9\\+\\-\\.]+)\\s+(.+)$', s)\n",
    "                if m3: k,v=m3.group(1).strip(),m3.group(2).strip()\n",
    "                else: continue\n",
    "        if k: m[k]=v\n",
    "    return m\n",
    "\n",
    "def extract_word_to_csv(docx_path, csv_out):\n",
    "    if not os.path.exists(docx_path):\n",
    "        raise FileNotFoundError(f\"æœªæ‰¾åˆ° Word æ–‡ä»¶: {docx_path}\")\n",
    "    doc = Document(docx_path)\n",
    "    seq = list(iter_ordered_blocks(doc))\n",
    "    results = []; i = 0\n",
    "    while i < len(seq):\n",
    "        typ,obj = seq[i]\n",
    "        if typ == 'p':\n",
    "            m = CMD_LINE_PAT.match(obj)\n",
    "            if m:\n",
    "                cmd, title = m.group(1), (m.group(2) or '').strip()\n",
    "                params_all = []; j = i + 1\n",
    "                while j < len(seq):\n",
    "                    t2,o2 = seq[j]\n",
    "                    if t2 == 'p' and is_cmd_heading(o2): break\n",
    "                    if t2 == 'p' and is_param_heading(o2):\n",
    "                        k = j + 1\n",
    "                        while k < len(seq) and seq[k][0] == 'tbl':\n",
    "                            table = seq[k][1]\n",
    "                            for r in table.rows:\n",
    "                                cols = r.cells\n",
    "                                if not any(c.text.strip() for c in cols): continue\n",
    "                                name = cell_plain_text(cols[0]) if len(cols)>0 else ''\n",
    "                                desc = cell_plain_text(cols[1]) if len(cols)>1 else ''\n",
    "                                valmap = {}\n",
    "                                if len(cols)>2:\n",
    "                                    valmap = cell_valmap_from_nested_table(cols[2]) or parse_enum_map_fuzzy(cell_plain_text(cols[2]))\n",
    "                                if not valmap and len(cols)>1:\n",
    "                                    valmap = cell_valmap_from_nested_table(cols[1]) or parse_enum_map_fuzzy(desc)\n",
    "                                if name in ('å‚æ•°','å‚æ•°å','Name') and any(x in desc for x in ['æè¿°','è¯´æ˜','Description']): continue\n",
    "                                params_all.append({'name':name,'desc':desc,'valmap':valmap})\n",
    "                            k += 1\n",
    "                        j = k; continue\n",
    "                    j += 1\n",
    "                if params_all:\n",
    "                    results.append({'å‘½ä»¤':cmd,'å‘½ä»¤æ ‡é¢˜':title,'å‘½ä»¤ç±»å‹':'æ‰§è¡Œ;æŸ¥è¯¢','å‘½ä»¤æ ¼å¼':cmd,\n",
    "                                    'ç¤ºä¾‹å‘½ä»¤':cmd,'ç¤ºä¾‹å“åº”':'','åŠŸèƒ½æè¿°':title,'å¤‡æ³¨':'',\n",
    "                                    'å‚æ•°JSON':json.dumps(params_all,ensure_ascii=False)})\n",
    "                i = j; continue\n",
    "        i += 1\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(csv_out,index=False,encoding='utf-8-sig')\n",
    "    print(f'âœ… æå– {len(df)} æ¡å‘½ä»¤ â†’ {csv_out}')\n",
    "    return df\n",
    "\n",
    "df_csv = extract_word_to_csv(IN_WORD, CSV_OUT)\n",
    "df_csv.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eba16c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2 â€” CSV â†’ YAMLï¼ˆä¿ç•™ valmapï¼‰\n",
    "import yaml, json\n",
    "YAML_OUT = os.path.join(CSV_DIR, \"all_commands.yaml\")\n",
    "\n",
    "def csv_to_yaml(csv_path, yaml_path):\n",
    "    df = pd.read_csv(csv_path, dtype=str).fillna(\"\")\n",
    "    cmds = []\n",
    "    for _,r in df.iterrows():\n",
    "        params = json.loads(r['å‚æ•°JSON']) if r['å‚æ•°JSON'] else []\n",
    "        cmds.append({\n",
    "            'command':r['å‘½ä»¤'],'title':r['å‘½ä»¤æ ‡é¢˜'],\n",
    "            'type':[t.strip() for t in r['å‘½ä»¤ç±»å‹'].split(';') if t.strip()],\n",
    "            'formats':[f.strip() for f in r['å‘½ä»¤æ ¼å¼'].split('|') if f.strip()] or [r['å‘½ä»¤æ ¼å¼']],\n",
    "            'parameters':params,\n",
    "            'examples':[{'cmd':c.strip(),'resp':e.strip()} for c,e in zip((r['ç¤ºä¾‹å‘½ä»¤'] or '').split('|'),(r['ç¤ºä¾‹å“åº”'] or '').split('|')) if c.strip() or e.strip()],\n",
    "            'description':r.get('åŠŸèƒ½æè¿°',''),'notes':r.get('å¤‡æ³¨','')\n",
    "        })\n",
    "    with open(yaml_path,'w',encoding='utf-8') as f:\n",
    "        yaml.safe_dump({'commands':cmds}, f, allow_unicode=True, sort_keys=False)\n",
    "    print(f'âœ… å·²ç”Ÿæˆ YAML â†’ {yaml_path}')\n",
    "\n",
    "csv_to_yaml(CSV_OUT, YAML_OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbca1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3 â€” YAML â†’ RSTï¼ˆä½¿ç”¨ p.valmap æ¨¡æ¿ï¼‰\n",
    "from jinja2 import Template\n",
    "import yaml, os\n",
    "\n",
    "RST_DIR = os.path.join(\"data\",\"rst_output\")\n",
    "os.makedirs(RST_DIR, exist_ok=True)\n",
    "\n",
    "TEMPLATE_STR = '''\n",
    "{{ cmd.command }}\n",
    "{{ '=' * cmd.command|length }}\n",
    "\n",
    "**Title**: {{ cmd.title }}\n",
    "**Types**: {{ cmd.type|join(', ') }}\n",
    "\n",
    "Formats::\n",
    "{%- for f in cmd.formats %}\n",
    "   {{ f }}\n",
    "{%- endfor %}\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ".. list-table::\n",
    "   :header-rows: 1\n",
    "   :widths: 18 34 48\n",
    "\n",
    "   * - Name\n",
    "     - Description\n",
    "     - Values\n",
    "{%- for p in cmd.parameters %}\n",
    "   * - {{ p.name }}\n",
    "     - {{ p.desc or 'â€”' }}\n",
    "     - {%- if p.valmap %}\n",
    "       .. list-table::\n",
    "          :header-rows: 1\n",
    "          :widths: 20 40\n",
    "\n",
    "          * - Key\n",
    "            - Value\n",
    "{%- for k,v in p.valmap.items() %}\n",
    "          * - {{ k }}\n",
    "            - {{ v }}\n",
    "{%- endfor %}\n",
    "       {%- else %} N/A {%- endif %}\n",
    "{%- endfor %}\n",
    "'''\n",
    "\n",
    "RST_TMPL = Template(TEMPLATE_STR)\n",
    "\n",
    "def yaml_to_rst(yaml_path, rst_dir):\n",
    "    with open(yaml_path, 'r', encoding='utf-8') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    cmds = data.get('commands', [])\n",
    "    for cmd in cmds:\n",
    "        text = RST_TMPL.render(cmd=cmd)\n",
    "        fname = f\"{cmd['command']}.rst\"\n",
    "        with open(os.path.join(rst_dir, fname), 'w', encoding='utf-8') as fo:\n",
    "            fo.write(text)\n",
    "    index_lines = ['AT Manual','=========','','.. toctree::','   :maxdepth: 1','']\n",
    "    for cmd in cmds:\n",
    "        index_lines.append(f\"   {cmd['command']}\")\n",
    "    with open(os.path.join(rst_dir,'index.rst'),'w',encoding='utf-8') as fo:\n",
    "        fo.write('\\n'.join(index_lines))\n",
    "    print(f'âœ… RST å·²ç”Ÿæˆåˆ° {rst_dir}')\n",
    "\n",
    "yaml_to_rst(YAML_OUT, RST_DIR)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
