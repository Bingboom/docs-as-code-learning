{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f253904b",
   "metadata": {},
   "source": [
    "# ğŸ“˜ Word â†’ CSV â†’ YAML â†’ RST â†’ Sphinx(HTML/PDF) å…¨è‡ªåŠ¨æµæ°´çº¿ v4\n",
    "æœ¬ç‰ˆæœ¬æ”¯æŒ **XML å±‚è§£æåµŒå¥—è¡¨æ ¼**ï¼Œç¡®ä¿å‚æ•°å–å€¼ä¸ä¼šä¸¢å¤±ï¼›å¹¶åœ¨ RST ä¸­æ¸²æŸ“ä¸ºå†…åµŒè¡¨æ ¼ã€‚\n",
    "å°† `at-parameter-demo.docx` æ”¾åœ¨ä¸æœ¬ Notebook åŒç›®å½•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95cc7c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0 â€” å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰\n",
    "!pip install -q python-docx pandas pyyaml jinja2 sphinx sphinx_rtd_theme lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930f3064",
   "metadata": {},
   "source": [
    "## Step 1 â€” Word â†’ CSVï¼ˆæ”¯æŒ XML å±‚åµŒå¥—è¡¨æ ¼è§£æï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ace05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æå– 3 æ¡å‘½ä»¤ â†’ data/extracted_commands.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>å‘½ä»¤</th>\n",
       "      <th>å‘½ä»¤æ ‡é¢˜</th>\n",
       "      <th>å‘½ä»¤ç±»å‹</th>\n",
       "      <th>å‘½ä»¤æ ¼å¼</th>\n",
       "      <th>ç¤ºä¾‹å‘½ä»¤</th>\n",
       "      <th>ç¤ºä¾‹å“åº”</th>\n",
       "      <th>åŠŸèƒ½æè¿°</th>\n",
       "      <th>å¤‡æ³¨</th>\n",
       "      <th>å‚æ•°JSON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATI</td>\n",
       "      <td>è·å–æ¨¡ç»„å‚å•†ä¿¡æ¯</td>\n",
       "      <td>æ‰§è¡Œ;æŸ¥è¯¢</td>\n",
       "      <td>ATI</td>\n",
       "      <td>ATI</td>\n",
       "      <td></td>\n",
       "      <td>è·å–æ¨¡ç»„å‚å•†ä¿¡æ¯</td>\n",
       "      <td></td>\n",
       "      <td>[{\"name\": \"&lt;manufacturer&gt;\", \"desc\": \"æ¨¡ç»„å‚å•†ä¿¡æ¯ã€äº§å“...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT+GMR</td>\n",
       "      <td>æŸ¥è¯¢ç‰ˆæœ¬ä¿¡æ¯</td>\n",
       "      <td>æ‰§è¡Œ;æŸ¥è¯¢</td>\n",
       "      <td>AT+GMR</td>\n",
       "      <td>AT+GMR</td>\n",
       "      <td></td>\n",
       "      <td>æŸ¥è¯¢ç‰ˆæœ¬ä¿¡æ¯</td>\n",
       "      <td></td>\n",
       "      <td>[{\"name\": \"&lt;reversion&gt;\", \"desc\": \"æ¨¡ç»„è½¯ä»¶ç‰ˆæœ¬ä¿¡æ¯\", \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT+CSQ</td>\n",
       "      <td>è·å–ä¿¡å·å¼ºåº¦</td>\n",
       "      <td>æ‰§è¡Œ;æŸ¥è¯¢</td>\n",
       "      <td>AT+CSQ</td>\n",
       "      <td>AT+CSQ</td>\n",
       "      <td></td>\n",
       "      <td>è·å–ä¿¡å·å¼ºåº¦</td>\n",
       "      <td></td>\n",
       "      <td>[{\"name\": \"&lt;signal&gt;\", \"desc\": \"ä¿¡å·å¼ºåº¦CSQ\", \"valu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       å‘½ä»¤      å‘½ä»¤æ ‡é¢˜   å‘½ä»¤ç±»å‹    å‘½ä»¤æ ¼å¼    ç¤ºä¾‹å‘½ä»¤ ç¤ºä¾‹å“åº”      åŠŸèƒ½æè¿° å¤‡æ³¨  \\\n",
       "0     ATI  è·å–æ¨¡ç»„å‚å•†ä¿¡æ¯  æ‰§è¡Œ;æŸ¥è¯¢     ATI     ATI       è·å–æ¨¡ç»„å‚å•†ä¿¡æ¯      \n",
       "1  AT+GMR    æŸ¥è¯¢ç‰ˆæœ¬ä¿¡æ¯  æ‰§è¡Œ;æŸ¥è¯¢  AT+GMR  AT+GMR         æŸ¥è¯¢ç‰ˆæœ¬ä¿¡æ¯      \n",
       "2  AT+CSQ    è·å–ä¿¡å·å¼ºåº¦  æ‰§è¡Œ;æŸ¥è¯¢  AT+CSQ  AT+CSQ         è·å–ä¿¡å·å¼ºåº¦      \n",
       "\n",
       "                                              å‚æ•°JSON  \n",
       "0  [{\"name\": \"<manufacturer>\", \"desc\": \"æ¨¡ç»„å‚å•†ä¿¡æ¯ã€äº§å“...  \n",
       "1  [{\"name\": \"<reversion>\", \"desc\": \"æ¨¡ç»„è½¯ä»¶ç‰ˆæœ¬ä¿¡æ¯\", \"...  \n",
       "2  [{\"name\": \"<signal>\", \"desc\": \"ä¿¡å·å¼ºåº¦CSQ\", \"valu...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, re, json\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.oxml.text.paragraph import CT_P\n",
    "from docx.oxml.table import CT_Tbl\n",
    "from lxml import etree\n",
    "\n",
    "IN_WORD = 'at-parameter-demo.docx'\n",
    "CSV_DIR = 'data'\n",
    "CSV_OUT = os.path.join(CSV_DIR, 'extracted_commands.csv')\n",
    "os.makedirs(CSV_DIR, exist_ok=True)\n",
    "\n",
    "def iter_ordered_blocks(doc):\n",
    "    body = doc._element.body\n",
    "    tbl_idx = 0\n",
    "    for child in body.iterchildren():\n",
    "        if isinstance(child, CT_P):\n",
    "            text = ''.join([t.text for t in child.xpath('.//w:t') if t.text]).strip()\n",
    "            yield ('p', text)\n",
    "        elif isinstance(child, CT_Tbl):\n",
    "            table_obj = doc.tables[tbl_idx]\n",
    "            tbl_idx += 1\n",
    "            yield ('tbl', table_obj)\n",
    "\n",
    "def cell_plain_text(cell):\n",
    "    parts = [p.text.strip() for p in cell.paragraphs if p.text and p.text.strip()]\n",
    "    return '\\n'.join(parts).strip()\n",
    "\n",
    "def cell_value_map_from_nested_table(cell):\n",
    "    xml_str = cell._tc.xml\n",
    "    root = etree.fromstring(xml_str.encode('utf-8'))\n",
    "    ns = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}\n",
    "    tables = root.findall('.//w:tbl', ns)\n",
    "    if not tables:\n",
    "        return {}\n",
    "    mapping = {}\n",
    "    for tbl in tables:\n",
    "        rows = tbl.findall('.//w:tr', ns)\n",
    "        for r in rows:\n",
    "            cells = r.findall('.//w:tc', ns)\n",
    "            if len(cells) >= 2:\n",
    "                k = ''.join(t.text for t in cells[0].iterfind('.//w:t', ns) if t.text).strip()\n",
    "                v = ''.join(t.text for t in cells[1].iterfind('.//w:t', ns) if t.text).strip()\n",
    "                if k:\n",
    "                    mapping[k] = v\n",
    "    return mapping\n",
    "\n",
    "def parse_enum_map_advanced(text):\n",
    "    if not text:\n",
    "        return {}\n",
    "    pairs = re.split(r'[ï¼Œ,;ï¼›\\n]+', text.strip())\n",
    "    result = {}\n",
    "    for p in pairs:\n",
    "        if ':' in p or 'ï¼š' in p:\n",
    "            k, v = re.split(r'[:ï¼š]', p, 1)\n",
    "            k, v = k.strip(), v.strip()\n",
    "            if k:\n",
    "                result[k] = v\n",
    "    return result\n",
    "\n",
    "def extract_word_to_csv(docx_path, csv_out):\n",
    "    doc = Document(docx_path)\n",
    "    seq = list(iter_ordered_blocks(doc))\n",
    "    cmd_line_pat = re.compile(r'^\\s*(AT\\S*?)\\s*[:ï¼š]\\s*(.*)$')\n",
    "    results = []\n",
    "    current_cmd = None\n",
    "    current_title = ''\n",
    "    wait_param_tbl = False\n",
    "\n",
    "    for typ, obj in seq:\n",
    "        if typ == 'p':\n",
    "            text = obj\n",
    "            m = cmd_line_pat.match(text)\n",
    "            if m:\n",
    "                current_cmd = m.group(1)\n",
    "                current_title = (m.group(2) or '').strip()\n",
    "                wait_param_tbl = False\n",
    "                continue\n",
    "            if text.strip() == 'å‚æ•°' and current_cmd:\n",
    "                wait_param_tbl = True\n",
    "                continue\n",
    "\n",
    "        elif typ == 'tbl' and current_cmd and wait_param_tbl:\n",
    "            table = obj\n",
    "            params = []\n",
    "            for r in table.rows:\n",
    "                cols = r.cells\n",
    "                if not any(c.text.strip() for c in cols):\n",
    "                    continue\n",
    "                name = cell_plain_text(cols[0]) if len(cols) > 0 else ''\n",
    "                desc = cell_plain_text(cols[1]) if len(cols) > 1 else ''\n",
    "                values = {}\n",
    "                if len(cols) > 2:\n",
    "                    values = cell_value_map_from_nested_table(cols[2])\n",
    "                    if not values:\n",
    "                        values = parse_enum_map_advanced(cell_plain_text(cols[2]))\n",
    "                if not values:\n",
    "                    values = cell_value_map_from_nested_table(cols[1]) or parse_enum_map_advanced(desc)\n",
    "\n",
    "                if name in ('å‚æ•°', 'å‚æ•°å', 'Name') and ('æè¿°' in desc or 'Description' in desc):\n",
    "                    continue\n",
    "\n",
    "                params.append({'name': name, 'desc': desc, 'values': values})\n",
    "\n",
    "            if params:\n",
    "                results.append({\n",
    "                    'å‘½ä»¤': current_cmd,\n",
    "                    'å‘½ä»¤æ ‡é¢˜': current_title,\n",
    "                    'å‘½ä»¤ç±»å‹': 'æ‰§è¡Œ;æŸ¥è¯¢',\n",
    "                    'å‘½ä»¤æ ¼å¼': current_cmd,\n",
    "                    'ç¤ºä¾‹å‘½ä»¤': current_cmd,\n",
    "                    'ç¤ºä¾‹å“åº”': '',\n",
    "                    'åŠŸèƒ½æè¿°': current_title,\n",
    "                    'å¤‡æ³¨': '',\n",
    "                    'å‚æ•°JSON': json.dumps(params, ensure_ascii=False)\n",
    "                })\n",
    "            wait_param_tbl = False\n",
    "            current_cmd = None\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(csv_out, index=False, encoding='utf-8-sig')\n",
    "    print(f'âœ… æå– {len(df)} æ¡å‘½ä»¤ â†’ {csv_out}')\n",
    "    return df\n",
    "\n",
    "df_csv = extract_word_to_csv(IN_WORD, CSV_OUT)\n",
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9f7b11",
   "metadata": {},
   "source": [
    "## Step 2 â€” CSV â†’ YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d18078b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²ç”Ÿæˆ YAML â†’ data/all_commands.yaml\n"
     ]
    }
   ],
   "source": [
    "import yaml, json\n",
    "YAML_OUT = os.path.join(CSV_DIR, 'all_commands.yaml')\n",
    "\n",
    "def csv_to_yaml(csv_path, yaml_path):\n",
    "    df = pd.read_csv(csv_path, dtype=str).fillna('')\n",
    "    cmd_objects = []\n",
    "    for _, r in df.iterrows():\n",
    "        params = json.loads(r['å‚æ•°JSON']) if r['å‚æ•°JSON'] else []\n",
    "        cmd_objects.append({\n",
    "            'command': r['å‘½ä»¤'],\n",
    "            'title': r['å‘½ä»¤æ ‡é¢˜'],\n",
    "            'type': [t.strip() for t in r['å‘½ä»¤ç±»å‹'].split(';') if t.strip()],\n",
    "            'formats': [f.strip() for f in r['å‘½ä»¤æ ¼å¼'].split('|') if f.strip()] or [r['å‘½ä»¤æ ¼å¼']],\n",
    "            'parameters': params,\n",
    "            'examples': [\n",
    "                {'cmd': c.strip(), 'resp': e.strip()}\n",
    "                for c, e in zip((r['ç¤ºä¾‹å‘½ä»¤'] or '').split('|'), (r['ç¤ºä¾‹å“åº”'] or '').split('|'))\n",
    "                if c.strip() or e.strip()\n",
    "            ],\n",
    "            'description': r.get('åŠŸèƒ½æè¿°',''),\n",
    "            'notes': r.get('å¤‡æ³¨','')\n",
    "        })\n",
    "    with open(yaml_path, 'w', encoding='utf-8') as f:\n",
    "        yaml.safe_dump({'commands': cmd_objects}, f, allow_unicode=True, sort_keys=False)\n",
    "    print(f'âœ… å·²ç”Ÿæˆ YAML â†’ {yaml_path}')\n",
    "\n",
    "csv_to_yaml(CSV_OUT, YAML_OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4ccd8",
   "metadata": {},
   "source": [
    "## Step 3 â€” YAML â†’ RSTï¼ˆæ¸²æŸ“åµŒå¥— values è¡¨æ ¼ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "028eed90",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedError",
     "evalue": "'builtin_function_or_method object' has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUndefinedError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 80\u001b[39m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mâœ… RST å·²ç”Ÿæˆåˆ° \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrst_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# ç”¨æ³•ç¤ºä¾‹ï¼ˆä½ åŸæ¥çš„å˜é‡åï¼‰\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m \u001b[43myaml_to_rst\u001b[49m\u001b[43m(\u001b[49m\u001b[43mYAML_OUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRST_DIR\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36myaml_to_rst\u001b[39m\u001b[34m(yaml_path, rst_dir)\u001b[39m\n\u001b[32m     66\u001b[39m cmds = data.get(\u001b[33m'\u001b[39m\u001b[33mcommands\u001b[39m\u001b[33m'\u001b[39m, [])\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cmd \u001b[38;5;129;01min\u001b[39;00m cmds:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     rst_text = \u001b[43mRST_TMPL\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m     fname = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcmd[\u001b[33m'\u001b[39m\u001b[33mcommand\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.rst\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os.path.join(rst_dir, fname), \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fo:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/docs-as-code-learning/.venv/lib/python3.13/site-packages/jinja2/environment.py:1295\u001b[39m, in \u001b[36mTemplate.render\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.environment.concat(\u001b[38;5;28mself\u001b[39m.root_render_func(ctx))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m   1294\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/docs-as-code-learning/.venv/lib/python3.13/site-packages/jinja2/environment.py:942\u001b[39m, in \u001b[36mEnvironment.handle_exception\u001b[39m\u001b[34m(self, source)\u001b[39m\n\u001b[32m    937\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Exception handling helper.  This is used internally to either raise\u001b[39;00m\n\u001b[32m    938\u001b[39m \u001b[33;03mrewritten exceptions or return a rendered traceback for the template.\u001b[39;00m\n\u001b[32m    939\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdebug\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rewrite_traceback_stack\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m rewrite_traceback_stack(source=source)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<template>:33\u001b[39m, in \u001b[36mtop-level template code\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/docs-as-code-learning/.venv/lib/python3.13/site-packages/jinja2/utils.py:92\u001b[39m, in \u001b[36m_PassArg.from_obj\u001b[39m\u001b[34m(cls, obj)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_obj\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj: F) -> t.Optional[\u001b[33m\"\u001b[39m\u001b[33m_PassArg\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjinja_pass_arg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m     93\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m obj.jinja_pass_arg  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mUndefinedError\u001b[39m: 'builtin_function_or_method object' has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "from jinja2 import Template\n",
    "import yaml, os\n",
    "\n",
    "RST_DIR = os.path.join('data', 'rst_output')\n",
    "os.makedirs(RST_DIR, exist_ok=True)\n",
    "\n",
    "RST_TMPL = Template('''\n",
    "{{ cmd.command }}\n",
    "{{ '=' * cmd.command|length }}\n",
    "\n",
    "**Title**: {{ cmd.title }}\n",
    "**Types**: {{ cmd.type|join(', ') }}\n",
    "\n",
    "Formats::\n",
    "{%- for f in cmd.formats %}\n",
    "   {{ f }}\n",
    "{%- endfor %}\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ".. list-table::\n",
    "   :header-rows: 1\n",
    "   :widths: 18 34 48\n",
    "\n",
    "   * - Name\n",
    "     - Description\n",
    "     - Values\n",
    "{%- for p in cmd.parameters %}\n",
    "   * - {{ p.name }}\n",
    "     - {{ p.desc or 'â€”' }}\n",
    "     - {%- if p.values is defined and p.values and p.values.items is defined %}\n",
    "       \n",
    "       .. list-table::\n",
    "          :header-rows: 1\n",
    "          :widths: 20 40\n",
    "\n",
    "          * - Key\n",
    "            - Value\n",
    "{%- for k,v in p.values.items() %}\n",
    "          * - {{ k }}\n",
    "            - {{ v }}\n",
    "{%- endfor %}\n",
    "       {%- else %} N/A {%- endif %}\n",
    "{%- endfor %}\n",
    "\n",
    "Examples\n",
    "--------\n",
    "{%- for ex in cmd.examples %}\n",
    ".. code-block:: none\n",
    "\n",
    "   {{ ex.cmd }}\n",
    "   {{ ex.resp }}\n",
    "{%- endfor %}\n",
    "\n",
    "**Description**: {{ cmd.description or '' }}\n",
    "\n",
    "{%- if cmd.notes %}\n",
    "**Notes**: {{ cmd.notes }}\n",
    "{%- endif %}\n",
    "''')\n",
    "\n",
    "def yaml_to_rst(yaml_path, rst_dir):\n",
    "    with open(yaml_path, 'r', encoding='utf-8') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    cmds = data.get('commands', [])\n",
    "    # å¼ºåˆ¶ç¡®ä¿æ¯ä¸ª parameter çš„ values éƒ½æ˜¯ dictï¼ˆé˜²æ­¢ None æˆ–å…¶ä»–ç±»å‹å¸¦æ¥æ¨¡æ¿æŠ¥é”™ï¼‰\n",
    "    for cmd in cmds:\n",
    "        for p in cmd.get('parameters', []):\n",
    "            if not isinstance(p.get('values', {}), dict):\n",
    "                p['values'] = {}\n",
    "    for cmd in cmds:\n",
    "        rst_text = RST_TMPL.render(cmd=cmd)\n",
    "        fname = f\"{cmd['command']}.rst\"\n",
    "        with open(os.path.join(rst_dir, fname), 'w', encoding='utf-8') as fo:\n",
    "            fo.write(rst_text)\n",
    "    index_lines = ['AT Manual', '=========', '', '.. toctree::', '   :maxdepth: 1', '']\n",
    "    for cmd in cmds:\n",
    "        index_lines.append(f\"   {cmd['command']}\")\n",
    "    with open(os.path.join(rst_dir, 'index.rst'), 'w', encoding='utf-8') as fo:\n",
    "        fo.write('\\n'.join(index_lines))\n",
    "    print(f'âœ… RST å·²ç”Ÿæˆåˆ° {rst_dir}')\n",
    "\n",
    "# ç”¨æ³•ç¤ºä¾‹\n",
    "yaml_to_rst(YAML_OUT, RST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9905038",
   "metadata": {},
   "source": [
    "## Step 4 â€” åˆå§‹åŒ– Sphinxï¼ˆå­˜åœ¨åˆ™è·³è¿‡ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df975e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ docs/ å·²å­˜åœ¨ï¼Œè·³è¿‡ sphinx-quickstart åˆå§‹åŒ–ã€‚\n",
      "âœ… RST å·²å¤åˆ¶åˆ° docs/source/\n"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "DOCS_DIR = 'docs'\n",
    "if not os.path.exists(DOCS_DIR):\n",
    "    !sphinx-quickstart {DOCS_DIR} --sep --project 'AT Command Manual' --author 'Doc Team' --release '1.0' -q\n",
    "else:\n",
    "    print('âš ï¸ docs/ å·²å­˜åœ¨ï¼Œè·³è¿‡ sphinx-quickstart åˆå§‹åŒ–ã€‚')\n",
    "\n",
    "conf_py = os.path.join(DOCS_DIR, 'source', 'conf.py')\n",
    "if os.path.exists(conf_py):\n",
    "    with open(conf_py, 'a', encoding='utf-8') as f:\n",
    "        f.write('\\nhtml_theme = \"sphinx_rtd_theme\"\\n')\n",
    "\n",
    "shutil.copytree('data/rst_output', os.path.join(DOCS_DIR, 'source'), dirs_exist_ok=True)\n",
    "print('âœ… RST å·²å¤åˆ¶åˆ° docs/source/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f52fd73",
   "metadata": {},
   "source": [
    "## Step 5 â€” æ„å»º HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbedd981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01mRunning Sphinx v8.2.3\u001b[39;49;00m\n",
      "\u001b[01mloading translations [en]... \u001b[39;49;00mdone\n",
      "\u001b[01mloading pickled environment... \u001b[39;49;00mfailed: source directory has changed\n",
      "done\n",
      "\u001b[01mbuilding [mo]: \u001b[39;49;00mtargets for 0 po files that are out of date\n",
      "\u001b[01mwriting output... \u001b[39;49;00m\n",
      "\u001b[01mbuilding [html]: \u001b[39;49;00mtargets for 4 source files that are out of date\n",
      "\u001b[01mupdating environment: \u001b[39;49;00m[new config] 4 added, 0 changed, 0 removed\n",
      "\u001b[2K\u001b[01mreading sources... \u001b[39;49;00m[100%] \u001b[35mindex\u001b[39;49;00mm\n",
      "\u001b[01mlooking for now-outdated files... \u001b[39;49;00mnone found\n",
      "\u001b[01mpickling environment... \u001b[39;49;00mdone\n",
      "\u001b[01mchecking consistency... \u001b[39;49;00mdone\n",
      "\u001b[01mpreparing documents... \u001b[39;49;00mdone\n",
      "\u001b[01mcopying assets... \u001b[39;49;00m\n",
      "\u001b[01mcopying static files... \u001b[39;49;00m\n",
      "Writing evaluated template result to /Users/pika/Documents/GitHub/docs-as-code-learning/pipeline-1008/docs/build/html/_static/basic.css\n",
      "Writing evaluated template result to /Users/pika/Documents/GitHub/docs-as-code-learning/pipeline-1008/docs/build/html/_static/language_data.js\n",
      "Writing evaluated template result to /Users/pika/Documents/GitHub/docs-as-code-learning/pipeline-1008/docs/build/html/_static/documentation_options.js\n",
      "Writing evaluated template result to /Users/pika/Documents/GitHub/docs-as-code-learning/pipeline-1008/docs/build/html/_static/js/versions.js\n",
      "\u001b[01mcopying static files: \u001b[39;49;00mdone\n",
      "\u001b[01mcopying extra files... \u001b[39;49;00m\n",
      "\u001b[01mcopying extra files: \u001b[39;49;00mdone\n",
      "\u001b[01mcopying assets: \u001b[39;49;00mdone\n",
      "\u001b[2K\u001b[01mwriting output... \u001b[39;49;00m[100%] \u001b[32mindex\u001b[39;49;00mm\n",
      "\u001b[01mgenerating indices... \u001b[39;49;00mgenindex done\n",
      "\u001b[01mwriting additional pages... \u001b[39;49;00msearch done\n",
      "\u001b[01mdumping search index in English (code: en)... \u001b[39;49;00mdone\n",
      "\u001b[01mdumping object inventory... \u001b[39;49;00mdone\n",
      "\u001b[01mbuild succeeded.\u001b[39;49;00m\n",
      "\n",
      "The HTML pages are in build/html.\n",
      "\n",
      "âœ… æ„å»ºå®Œæˆï¼Œæ‰“å¼€ï¼šdocs/build/html/index.html\n"
     ]
    }
   ],
   "source": [
    "!make -C docs html\n",
    "print('\\nâœ… æ„å»ºå®Œæˆï¼Œæ‰“å¼€ï¼šdocs/build/html/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667b4745",
   "metadata": {},
   "source": [
    "## ğŸŸ¢ ä¸€é”®æ‰§è¡Œï¼šrun_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3408e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‡†å¤‡å°±ç»ªã€‚é€æ­¥è¿è¡Œæˆ–ç›´æ¥ run_all()ã€‚\n"
     ]
    }
   ],
   "source": [
    "def run_all():\n",
    "    global df_csv\n",
    "    df_csv = extract_word_to_csv(IN_WORD, CSV_OUT)\n",
    "    csv_to_yaml(CSV_OUT, YAML_OUT)\n",
    "    yaml_to_rst(YAML_OUT, RST_DIR)\n",
    "    import shutil, os\n",
    "    if not os.path.exists('docs'):\n",
    "        get_ipython().run_cell_magic('bash', '', 'sphinx-quickstart docs --sep --project \"AT Command Manual\" --author \"Doc Team\" --release \"1.0\" -q')\n",
    "    with open('docs/source/conf.py','a',encoding='utf-8') as f:\n",
    "        f.write('\\nhtml_theme = \"sphinx_rtd_theme\"\\n')\n",
    "    shutil.copytree('data/rst_output', 'docs/source', dirs_exist_ok=True)\n",
    "    get_ipython().run_cell_magic('bash', '', 'make -C docs html')\n",
    "    print('\\nâœ… å®Œæˆï¼šdocs/build/html/index.html')\n",
    "print('å‡†å¤‡å°±ç»ªã€‚é€æ­¥è¿è¡Œæˆ–ç›´æ¥ run_all()ã€‚')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
