{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f253904b",
   "metadata": {},
   "source": [
    "# ğŸ“˜ Word â†’ CSV â†’ YAML â†’ RST â†’ Sphinx(HTML/PDF) å…¨è‡ªåŠ¨æµæ°´çº¿ v4\n",
    "æœ¬ç‰ˆæœ¬æ”¯æŒ **XML å±‚è§£æåµŒå¥—è¡¨æ ¼**ï¼Œç¡®ä¿å‚æ•°å–å€¼ä¸ä¼šä¸¢å¤±ï¼›å¹¶åœ¨ RST ä¸­æ¸²æŸ“ä¸ºå†…åµŒè¡¨æ ¼ã€‚\n",
    "å°† `at-parameter-demo.docx` æ”¾åœ¨ä¸æœ¬ Notebook åŒç›®å½•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cc7c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0 â€” å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰\n",
    "!pip install -q python-docx pandas pyyaml jinja2 sphinx sphinx_rtd_theme lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930f3064",
   "metadata": {},
   "source": [
    "## Step 1 â€” Word â†’ CSVï¼ˆæ”¯æŒ XML å±‚åµŒå¥—è¡¨æ ¼è§£æï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ace05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.oxml.text.paragraph import CT_P\n",
    "from docx.oxml.table import CT_Tbl\n",
    "from lxml import etree\n",
    "\n",
    "IN_WORD = 'at-parameter-demo.docx'\n",
    "CSV_DIR = 'data'\n",
    "CSV_OUT = os.path.join(CSV_DIR, 'extracted_commands.csv')\n",
    "os.makedirs(CSV_DIR, exist_ok=True)\n",
    "\n",
    "def iter_ordered_blocks(doc):\n",
    "    body = doc._element.body\n",
    "    tbl_idx = 0\n",
    "    for child in body.iterchildren():\n",
    "        if isinstance(child, CT_P):\n",
    "            text = ''.join([t.text for t in child.xpath('.//w:t') if t.text]).strip()\n",
    "            yield ('p', text)\n",
    "        elif isinstance(child, CT_Tbl):\n",
    "            table_obj = doc.tables[tbl_idx]\n",
    "            tbl_idx += 1\n",
    "            yield ('tbl', table_obj)\n",
    "\n",
    "def cell_plain_text(cell):\n",
    "    parts = [p.text.strip() for p in cell.paragraphs if p.text and p.text.strip()]\n",
    "    return '\\n'.join(parts).strip()\n",
    "\n",
    "def cell_value_map_from_nested_table(cell):\n",
    "    xml_str = cell._tc.xml\n",
    "    root = etree.fromstring(xml_str.encode('utf-8'))\n",
    "    ns = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}\n",
    "    tables = root.findall('.//w:tbl', ns)\n",
    "    if not tables:\n",
    "        return {}\n",
    "    mapping = {}\n",
    "    for tbl in tables:\n",
    "        rows = tbl.findall('.//w:tr', ns)\n",
    "        for r in rows:\n",
    "            cells = r.findall('.//w:tc', ns)\n",
    "            if len(cells) >= 2:\n",
    "                k = ''.join(t.text for t in cells[0].iterfind('.//w:t', ns) if t.text).strip()\n",
    "                v = ''.join(t.text for t in cells[1].iterfind('.//w:t', ns) if t.text).strip()\n",
    "                if k:\n",
    "                    mapping[k] = v\n",
    "    return mapping\n",
    "\n",
    "def parse_enum_map_advanced(text):\n",
    "    if not text:\n",
    "        return {}\n",
    "    pairs = re.split(r'[ï¼Œ,;ï¼›\\n]+', text.strip())\n",
    "    result = {}\n",
    "    for p in pairs:\n",
    "        if ':' in p or 'ï¼š' in p:\n",
    "            k, v = re.split(r'[:ï¼š]', p, 1)\n",
    "            k, v = k.strip(), v.strip()\n",
    "            if k:\n",
    "                result[k] = v\n",
    "    return result\n",
    "\n",
    "def extract_word_to_csv(docx_path, csv_out):\n",
    "    doc = Document(docx_path)\n",
    "    seq = list(iter_ordered_blocks(doc))\n",
    "    cmd_line_pat = re.compile(r'^\\s*(AT\\S*?)\\s*[:ï¼š]\\s*(.*)$')\n",
    "    results = []\n",
    "    current_cmd = None\n",
    "    current_title = ''\n",
    "    wait_param_tbl = False\n",
    "\n",
    "    for typ, obj in seq:\n",
    "        if typ == 'p':\n",
    "            text = obj\n",
    "            m = cmd_line_pat.match(text)\n",
    "            if m:\n",
    "                current_cmd = m.group(1)\n",
    "                current_title = (m.group(2) or '').strip()\n",
    "                wait_param_tbl = False\n",
    "                continue\n",
    "            if text.strip() == 'å‚æ•°' and current_cmd:\n",
    "                wait_param_tbl = True\n",
    "                continue\n",
    "\n",
    "        elif typ == 'tbl' and current_cmd and wait_param_tbl:\n",
    "            table = obj\n",
    "            params = []\n",
    "            for r in table.rows:\n",
    "                cols = r.cells\n",
    "                if not any(c.text.strip() for c in cols):\n",
    "                    continue\n",
    "                name = cell_plain_text(cols[0]) if len(cols) > 0 else ''\n",
    "                desc = cell_plain_text(cols[1]) if len(cols) > 1 else ''\n",
    "                values = {}\n",
    "                if len(cols) > 2:\n",
    "                    values = cell_value_map_from_nested_table(cols[2])\n",
    "                    if not values:\n",
    "                        values = parse_enum_map_advanced(cell_plain_text(cols[2]))\n",
    "                if not values:\n",
    "                    values = cell_value_map_from_nested_table(cols[1]) or parse_enum_map_advanced(desc)\n",
    "\n",
    "                if name in ('å‚æ•°', 'å‚æ•°å', 'Name') and ('æè¿°' in desc or 'Description' in desc):\n",
    "                    continue\n",
    "\n",
    "                params.append({'name': name, 'desc': desc, 'values': values})\n",
    "\n",
    "            if params:\n",
    "                results.append({\n",
    "                    'å‘½ä»¤': current_cmd,\n",
    "                    'å‘½ä»¤æ ‡é¢˜': current_title,\n",
    "                    'å‘½ä»¤ç±»å‹': 'æ‰§è¡Œ;æŸ¥è¯¢',\n",
    "                    'å‘½ä»¤æ ¼å¼': current_cmd,\n",
    "                    'ç¤ºä¾‹å‘½ä»¤': current_cmd,\n",
    "                    'ç¤ºä¾‹å“åº”': '',\n",
    "                    'åŠŸèƒ½æè¿°': current_title,\n",
    "                    'å¤‡æ³¨': '',\n",
    "                    'å‚æ•°JSON': json.dumps(params, ensure_ascii=False)\n",
    "                })\n",
    "            wait_param_tbl = False\n",
    "            current_cmd = None\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(csv_out, index=False, encoding='utf-8-sig')\n",
    "    print(f'âœ… æå– {len(df)} æ¡å‘½ä»¤ â†’ {csv_out}')\n",
    "    return df\n",
    "\n",
    "df_csv = extract_word_to_csv(IN_WORD, CSV_OUT)\n",
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9f7b11",
   "metadata": {},
   "source": [
    "## Step 2 â€” CSV â†’ YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18078b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml, json\n",
    "YAML_OUT = os.path.join(CSV_DIR, 'all_commands.yaml')\n",
    "\n",
    "def csv_to_yaml(csv_path, yaml_path):\n",
    "    df = pd.read_csv(csv_path, dtype=str).fillna('')\n",
    "    cmd_objects = []\n",
    "    for _, r in df.iterrows():\n",
    "        params = json.loads(r['å‚æ•°JSON']) if r['å‚æ•°JSON'] else []\n",
    "        cmd_objects.append({\n",
    "            'command': r['å‘½ä»¤'],\n",
    "            'title': r['å‘½ä»¤æ ‡é¢˜'],\n",
    "            'type': [t.strip() for t in r['å‘½ä»¤ç±»å‹'].split(';') if t.strip()],\n",
    "            'formats': [f.strip() for f in r['å‘½ä»¤æ ¼å¼'].split('|') if f.strip()] or [r['å‘½ä»¤æ ¼å¼']],\n",
    "            'parameters': params,\n",
    "            'examples': [\n",
    "                {'cmd': c.strip(), 'resp': e.strip()}\n",
    "                for c, e in zip((r['ç¤ºä¾‹å‘½ä»¤'] or '').split('|'), (r['ç¤ºä¾‹å“åº”'] or '').split('|'))\n",
    "                if c.strip() or e.strip()\n",
    "            ],\n",
    "            'description': r.get('åŠŸèƒ½æè¿°',''),\n",
    "            'notes': r.get('å¤‡æ³¨','')\n",
    "        })\n",
    "    with open(yaml_path, 'w', encoding='utf-8') as f:\n",
    "        yaml.safe_dump({'commands': cmd_objects}, f, allow_unicode=True, sort_keys=False)\n",
    "    print(f'âœ… å·²ç”Ÿæˆ YAML â†’ {yaml_path}')\n",
    "\n",
    "csv_to_yaml(CSV_OUT, YAML_OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4ccd8",
   "metadata": {},
   "source": [
    "## Step 3 â€” YAML â†’ RSTï¼ˆæ¸²æŸ“åµŒå¥— values è¡¨æ ¼ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028eed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "import yaml, os\n",
    "RST_DIR = os.path.join('data', 'rst_output')\n",
    "os.makedirs(RST_DIR, exist_ok=True)\n",
    "\n",
    "RST_TMPL = Template('''\n",
    "{{ cmd.command }}\n",
    "{{ '=' * cmd.command|length }}\n",
    "\n",
    "**Title**: {{ cmd.title }}\n",
    "**Types**: {{ cmd.type|join(', ') }}\n",
    "\n",
    "Formats::\n",
    "{%- for f in cmd.formats %}\n",
    "   {{ f }}\n",
    "{%- endfor %}\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ".. list-table::\n",
    "   :header-rows: 1\n",
    "   :widths: 18 34 48\n",
    "\n",
    "   * - Name\n",
    "     - Description\n",
    "     - Values\n",
    "{%- for p in cmd.parameters %}\n",
    "   * - {{ p.name }}\n",
    "     - {{ p.desc or 'â€”' }}\n",
    "     - {%- if p.values is mapping and p.values|length > 0 %}\n",
    "\n",
    "       .. list-table::\n",
    "          :header-rows: 1\n",
    "          :widths: 20 40\n",
    "\n",
    "          * - Key\n",
    "            - Value\n",
    "{%- for k,v in p.values.items() %}\n",
    "          * - {{ k }}\n",
    "            - {{ v }}\n",
    "{%- endfor %}\n",
    "       {%- else %} N/A {%- endif %}\n",
    "{%- endfor %}\n",
    "\n",
    "Examples\n",
    "--------\n",
    "{%- for ex in cmd.examples %}\n",
    ".. code-block:: none\n",
    "\n",
    "   {{ ex.cmd }}\n",
    "   {{ ex.resp }}\n",
    "{%- endfor %}\n",
    "\n",
    "**Description**: {{ cmd.description or '' }}\n",
    "\n",
    "{%- if cmd.notes %}\n",
    "**Notes**: {{ cmd.notes }}\n",
    "{%- endif %}\n",
    "''')\n",
    "\n",
    "def yaml_to_rst(yaml_path, rst_dir):\n",
    "    with open(yaml_path, 'r', encoding='utf-8') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    cmds = data.get('commands', [])\n",
    "    for cmd in cmds:\n",
    "        rst_text = RST_TMPL.render(cmd=cmd)\n",
    "        fname = f\"{cmd['command']}.rst\"\n",
    "        with open(os.path.join(rst_dir, fname), 'w', encoding='utf-8') as fo:\n",
    "            fo.write(rst_text)\n",
    "    index_lines = ['AT Manual', '=========', '', '.. toctree::', '   :maxdepth: 1', '']\n",
    "    for cmd in cmds:\n",
    "        index_lines.append(f\"   {cmd['command']}\")\n",
    "    with open(os.path.join(rst_dir, 'index.rst'), 'w', encoding='utf-8') as fo:\n",
    "        fo.write('\\n'.join(index_lines))\n",
    "    print(f'âœ… RST å·²ç”Ÿæˆåˆ° {rst_dir}')\n",
    "\n",
    "yaml_to_rst(YAML_OUT, RST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9905038",
   "metadata": {},
   "source": [
    "## Step 4 â€” åˆå§‹åŒ– Sphinxï¼ˆå­˜åœ¨åˆ™è·³è¿‡ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df975e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "DOCS_DIR = 'docs'\n",
    "if not os.path.exists(DOCS_DIR):\n",
    "    !sphinx-quickstart {DOCS_DIR} --sep --project 'AT Command Manual' --author 'Doc Team' --release '1.0' -q\n",
    "else:\n",
    "    print('âš ï¸ docs/ å·²å­˜åœ¨ï¼Œè·³è¿‡ sphinx-quickstart åˆå§‹åŒ–ã€‚')\n",
    "\n",
    "conf_py = os.path.join(DOCS_DIR, 'source', 'conf.py')\n",
    "if os.path.exists(conf_py):\n",
    "    with open(conf_py, 'a', encoding='utf-8') as f:\n",
    "        f.write('\\nhtml_theme = \"sphinx_rtd_theme\"\\n')\n",
    "\n",
    "shutil.copytree('data/rst_output', os.path.join(DOCS_DIR, 'source'), dirs_exist_ok=True)\n",
    "print('âœ… RST å·²å¤åˆ¶åˆ° docs/source/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f52fd73",
   "metadata": {},
   "source": [
    "## Step 5 â€” æ„å»º HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbedd981",
   "metadata": {},
   "outputs": [],
   "source": [
    "!make -C docs html\n",
    "print('\\nâœ… æ„å»ºå®Œæˆï¼Œæ‰“å¼€ï¼šdocs/build/html/index.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667b4745",
   "metadata": {},
   "source": [
    "## ğŸŸ¢ ä¸€é”®æ‰§è¡Œï¼šrun_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3408e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all():\n",
    "    global df_csv\n",
    "    df_csv = extract_word_to_csv(IN_WORD, CSV_OUT)\n",
    "    csv_to_yaml(CSV_OUT, YAML_OUT)\n",
    "    yaml_to_rst(YAML_OUT, RST_DIR)\n",
    "    import shutil, os\n",
    "    if not os.path.exists('docs'):\n",
    "        get_ipython().run_cell_magic('bash', '', 'sphinx-quickstart docs --sep --project \"AT Command Manual\" --author \"Doc Team\" --release \"1.0\" -q')\n",
    "    with open('docs/source/conf.py','a',encoding='utf-8') as f:\n",
    "        f.write('\\nhtml_theme = \"sphinx_rtd_theme\"\\n')\n",
    "    shutil.copytree('data/rst_output', 'docs/source', dirs_exist_ok=True)\n",
    "    get_ipython().run_cell_magic('bash', '', 'make -C docs html')\n",
    "    print('\\nâœ… å®Œæˆï¼šdocs/build/html/index.html')\n",
    "print('å‡†å¤‡å°±ç»ªã€‚é€æ­¥è¿è¡Œæˆ–ç›´æ¥ run_all()ã€‚')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
