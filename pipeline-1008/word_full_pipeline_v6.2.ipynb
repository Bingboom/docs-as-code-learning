{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📘 word_full_pipeline_v6.2 — Word → CSV → YAML → RST → Sphinx(HTML/PDF)\n",
    "适配复杂 AT 命令手册（嵌套表、合并单元格、多参数表）。输入 `AT_Commands.docx`，输出 HTML（可选 PDF）。\n",
    "\n",
    "**v6.2 关键增强**\n",
    "- 初始化 Sphinx 前**自动清理**旧项目；\n",
    "- 使用 `sphinx-build` 构建并**自动降级 docutils** 失败回退；\n",
    "- 延续 v6 的**嵌套表优先 / 文本回退**（生成 `valmap`）；\n",
    "- 生成解析日志 `parse_log.txt`；\n",
    "- 一键 `run_all(clean=True)`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 — 安装依赖（首次运行需要）"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install -q python-docx pandas pyyaml jinja2 sphinx sphinx_rtd_theme lxml\n",
    "print(\"✅ 依赖安装完成\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0.5 — 配置与通用工具（路径、日志、目录查看）"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os, re, json, traceback, datetime, subprocess, sys, shutil\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "from docx import Document\n",
    "from docx.oxml.text.paragraph import CT_P\n",
    "from docx.oxml.table import CT_Tbl\n",
    "\n",
    "IN_WORD = \"AT_Commands.docx\"\n",
    "DATA_DIR = \"data\"\n",
    "CSV_OUT  = os.path.join(DATA_DIR, \"at_extracted_commands.csv\")\n",
    "YAML_OUT = os.path.join(DATA_DIR, \"at_all_commands.yaml\")\n",
    "RST_DIR  = os.path.join(DATA_DIR, \"rst_output\")\n",
    "DOCS_DIR = \"docs\"\n",
    "LOG_PATH = \"parse_log.txt\"\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(RST_DIR, exist_ok=True)\n",
    "\n",
    "def log(msg: str):\n",
    "    with open(LOG_PATH, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"[{datetime.datetime.now().isoformat(timespec='seconds')}] {msg}\\n\")\n",
    "\n",
    "open(LOG_PATH, \"w\", encoding=\"utf-8\").write(\"\")\n",
    "\n",
    "def print_tree(root=\"docs\"):\n",
    "    if not os.path.exists(root):\n",
    "        print(f\"(不存在) {root}\")\n",
    "        return\n",
    "    for dirpath, dirnames, filenames in os.walk(root):\n",
    "        level = dirpath.replace(root, \"\").count(os.sep)\n",
    "        indent = \"  \" * level\n",
    "        print(f\"{indent}{os.path.basename(dirpath)}/\")\n",
    "        subindent = \"  \" * (level + 1)\n",
    "        for f in filenames:\n",
    "            print(f\"{subindent}{f}\")\n",
    "print(\"✅ 配置就绪；可用 print_tree('docs') 查看 Sphinx 目录结构\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 — Word → CSV（复杂解析：嵌套表、多表合并、valmap）\n",
    "- 识别命令标题；合并后续说明段；\n",
    "- 连续参数表自动合并；\n",
    "- 优先解析嵌套表为 `valmap`，否则回退文本解析；\n",
    "- 日志写入 `parse_log.txt`。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "CMD_LINE_PAT = re.compile(r'^\\s*(AT[\\+\\w\\-]+(?:\\?[=\\w<>,\\s\\-\\+\\.\\:]*?)?)\\s*(?::|：)?\\s*(.*)$', re.I)\n",
    "PARAM_HEADING_PAT = re.compile(r'^\\s*参数(说明|表|信息)?\\s*[:：]?\\s*$', re.I)\n",
    "\n",
    "def is_cmd_heading(text: str) -> bool: return bool(CMD_LINE_PAT.match(text or \"\"))\n",
    "def is_param_heading(text: str) -> bool: return bool(PARAM_HEADING_PAT.match(text or \"\"))\n",
    "\n",
    "def iter_ordered_blocks(doc):\n",
    "    body = doc._element.body\n",
    "    tbl_idx = 0\n",
    "    for child in body.iterchildren():\n",
    "        if isinstance(child, CT_P):\n",
    "            text = \"\".join([t.text for t in child.xpath('.//w:t') if t.text]).strip()\n",
    "            yield (\"p\", text)\n",
    "        elif isinstance(child, CT_Tbl):\n",
    "            table_obj = doc.tables[tbl_idx]\n",
    "            tbl_idx += 1\n",
    "            yield (\"tbl\", table_obj)\n",
    "\n",
    "def cell_plain_text(cell):\n",
    "    parts = [p.text.strip() for p in cell.paragraphs if p.text and p.text.strip()]\n",
    "    return \"\\n\".join(parts).strip()\n",
    "\n",
    "def find_nested_tbls_in_cell(cell):\n",
    "    xml_str = cell._tc.xml\n",
    "    root = etree.fromstring(xml_str.encode(\"utf-8\"))\n",
    "    ns = {\"w\": \"http://schemas.openxmlformats.org/wordprocessingml/2006/main\"}\n",
    "    return root.findall(\".//w:tbl\", ns), ns\n",
    "\n",
    "def tbl_rows_as_text(tbl, ns):\n",
    "    rows = []\n",
    "    for r in tbl.findall(\".//w:tr\", ns):\n",
    "        cells = r.findall(\".//w:tc\", ns)\n",
    "        row = [\"\".join(tn.text for tn in c.iterfind(\".//w:t\", ns) if tn.text).strip() for c in cells]\n",
    "        rows.append(row)\n",
    "    return rows\n",
    "\n",
    "def looks_like_header(row):\n",
    "    hdr = \" \".join(row[:3])\n",
    "    return any(k in hdr for k in [\"参数\",\"名称\",\"Name\",\"描述\",\"说明\",\"含义\",\"取值\",\"值\",\"value\",\"meaning\",\"备注\",\"范围\"])\n",
    "\n",
    "def nested_table_to_valmap(rows):\n",
    "    if not rows: return {}\n",
    "    start = 1 if looks_like_header(rows[0]) else 0\n",
    "    kv = {}\n",
    "    for r in rows[start:]:\n",
    "        if not r: continue\n",
    "        key = (r[0] or \"\").strip()\n",
    "        val = \" | \".join([c for c in r[1:] if c and c.strip()]) if len(r) > 1 else \"\"\n",
    "        if key: kv[key] = val\n",
    "    return kv\n",
    "\n",
    "def cell_valmap_from_nested_table(cell):\n",
    "    tbls, ns = find_nested_tbls_in_cell(cell); mapping = {}\n",
    "    for t in tbls:\n",
    "        rows = tbl_rows_as_text(t, ns); mapping.update(nested_table_to_valmap(rows))\n",
    "    return mapping\n",
    "\n",
    "def parse_enum_map_fuzzy(text):\n",
    "    if not text: return {}\n",
    "    segs = re.split(r\"[,\\uFF0C;\\uFF1B\\n]+\", text.strip())\n",
    "    m = {}\n",
    "    for s in segs:\n",
    "        s = s.strip()\n",
    "        if not s: continue\n",
    "        if \":\" in s or \"：\" in s:\n",
    "            k, v = re.split(r\"[:：]\", s, 1); k, v = k.strip(), v.strip()\n",
    "        else:\n",
    "            m2 = re.match(r\"^(\\S+)\\s*(?:->|→|=>|-|—|\\s)\\s*(.+)$\", s)\n",
    "            if m2: k, v = m2.group(1).strip(), m2.group(2).strip()\n",
    "            else:\n",
    "                m3 = re.match(r\"^([A-Za-z0-9\\+\\-\\.]+)\\s+(.+)$\", s)\n",
    "                if m3: k, v = m3.group(1).strip(), m3.group(2).strip()\n",
    "                else: continue\n",
    "        if k: m[k] = v\n",
    "    return m\n",
    "\n",
    "def extract_word_to_csv(docx_path, csv_out):\n",
    "    if not os.path.exists(docx_path):\n",
    "        raise FileNotFoundError(f\"未找到 Word 文件: {docx_path}\")\n",
    "    log(f\"Start parsing: {docx_path}\")\n",
    "    doc = Document(docx_path)\n",
    "    seq = list(iter_ordered_blocks(doc))\n",
    "\n",
    "    results = []; i = 0; cmd_order = 0\n",
    "    while i < len(seq):\n",
    "        typ, obj = seq[i]\n",
    "        if typ == \"p\":\n",
    "            m = CMD_LINE_PAT.match(obj)\n",
    "            if m:\n",
    "                cmd_order += 1\n",
    "                current_cmd = m.group(1).strip()\n",
    "                current_title = (m.group(2) or \"\").strip()\n",
    "                log(f\"CMD[{cmd_order}] {current_cmd} — {current_title}\")\n",
    "\n",
    "                desc_lines = []; j = i + 1\n",
    "                while j < len(seq):\n",
    "                    t2, o2 = seq[j]\n",
    "                    if t2 == \"p\":\n",
    "                        if is_cmd_heading(o2) or is_param_heading(o2): break\n",
    "                        if o2: desc_lines.append(o2)\n",
    "                    elif t2 == \"tbl\": break\n",
    "                    j += 1\n",
    "                merged_desc = \"\\n\".join(desc_lines).strip()\n",
    "\n",
    "                params_all = []; table_count = 0; k = j\n",
    "                while k < len(seq):\n",
    "                    t3, o3 = seq[k]\n",
    "                    if t3 == \"p\" and is_cmd_heading(o3): break\n",
    "                    if t3 == \"p\" and is_param_heading(o3):\n",
    "                        k += 1\n",
    "                        while k < len(seq) and seq[k][0] == \"tbl\":\n",
    "                            table = seq[k][1]; table_count += 1\n",
    "                            for r in table.rows:\n",
    "                                cols = r.cells\n",
    "                                if not any(c.text.strip() for c in cols): continue\n",
    "                                try:\n",
    "                                    name = cell_plain_text(cols[0]) if len(cols) > 0 else \"\"\n",
    "                                    desc = cell_plain_text(cols[1]) if len(cols) > 1 else \"\"\n",
    "                                    valmap = {}\n",
    "                                    if len(cols) > 2:\n",
    "                                        valmap = cell_valmap_from_nested_table(cols[2]) or parse_enum_map_fuzzy(cell_plain_text(cols[2]))\n",
    "                                    if not valmap and len(cols) > 1:\n",
    "                                        valmap = cell_valmap_from_nested_table(cols[1]) or parse_enum_map_fuzzy(desc)\n",
    "                                    if name in (\"参数\",\"参数名\",\"Name\") and any(x in desc for x in [\"描述\",\"说明\",\"Description\",\"Meaning\"]): \n",
    "                                        continue\n",
    "                                    params_all.append({\"name\": name, \"desc\": desc, \"valmap\": valmap})\n",
    "                                except Exception as e:\n",
    "                                    log(f\"ROW-ERROR in {current_cmd}: {e}\")\n",
    "                                    log(traceback.format_exc())\n",
    "                            k += 1\n",
    "                        continue\n",
    "                    k += 1\n",
    "\n",
    "                if params_all or merged_desc:\n",
    "                    results.append({\n",
    "                        \"命令\": current_cmd, \"命令标题\": current_title, \"命令类型\": \"执行;查询\",\n",
    "                        \"命令格式\": current_cmd, \"示例命令\": current_cmd, \"示例响应\": \"\",\n",
    "                        \"功能描述\": merged_desc or current_title, \"备注\": \"\",\n",
    "                        \"表数量\": table_count, \"顺序\": cmd_order,\n",
    "                        \"参数JSON\": json.dumps(params_all, ensure_ascii=False)\n",
    "                    })\n",
    "                    log(f\"CMD[{cmd_order}] tables={table_count} params={len(params_all)}\")\n",
    "                i = k; continue\n",
    "        i += 1\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(csv_out, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ 提取 {len(df)} 条命令 → {csv_out}\")\n",
    "    print(f\"📝 解析日志：{LOG_PATH}\")\n",
    "    return df\n",
    "\n",
    "df_csv = extract_word_to_csv(IN_WORD, CSV_OUT)\n",
    "df_csv.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 — CSV → YAML（保留 valmap，增加 meta）"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import yaml\n",
    "def csv_to_yaml(csv_path, yaml_path):\n",
    "    df = pd.read_csv(csv_path, dtype=str).fillna(\"\")\n",
    "    objs = []\n",
    "    for _, r in df.iterrows():\n",
    "        params = json.loads(r[\"参数JSON\"]) if r[\"参数JSON\"] else []\n",
    "        objs.append({\n",
    "            \"command\": r[\"命令\"],\n",
    "            \"title\": r[\"命令标题\"],\n",
    "            \"type\": [t.strip() for t in r[\"命令类型\"].split(\";\") if t.strip()],\n",
    "            \"formats\": [f.strip() for f in r[\"命令格式\"].split(\"|\") if f.strip()] or [r[\"命令格式\"]],\n",
    "            \"parameters\": params,\n",
    "            \"examples\": [],\n",
    "            \"description\": r.get(\"功能描述\",\"\"),\n",
    "            \"notes\": r.get(\"备注\",\"\"),\n",
    "            \"meta\": {\"order\": int(r.get(\"顺序\",\"0\") or 0), \"tables\": int(r.get(\"表数量\",\"0\") or 0)}\n",
    "        })\n",
    "    objs.sort(key=lambda x: x[\"meta\"][\"order\"])\n",
    "    with open(yaml_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        yaml.safe_dump({\"commands\": objs}, f, allow_unicode=True, sort_keys=False)\n",
    "    print(f\"✅ 已生成 YAML → {yaml_path}\")\n",
    "csv_to_yaml(CSV_OUT, YAML_OUT)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 — YAML → RST（valmap 模板渲染 + 分组索引）"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from jinja2 import Template\n",
    "from collections import defaultdict\n",
    "\n",
    "PAGE_TMPL = Template('''\n",
    "{{ cmd.command }}\n",
    "{{ '=' * cmd.command|length }}\n",
    "\n",
    "**Title**: {{ cmd.title }}\n",
    "**Types**: {{ cmd.type|join(', ') }}\n",
    "\n",
    "Formats::\n",
    "{%- for f in cmd.formats %}\n",
    "   {{ f }}\n",
    "{%- endfor %}\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ".. list-table::\n",
    "   :header-rows: 1\n",
    "   :widths: 18 34 48\n",
    "\n",
    "   * - Name\n",
    "     - Description\n",
    "     - Values\n",
    "{%- for p in cmd.parameters %}\n",
    "   * - {{ p.name }}\n",
    "     - {{ p.desc or '—' }}\n",
    "     - {%- if p.valmap %}\n",
    "       .. list-table::\n",
    "          :header-rows: 1\n",
    "          :widths: 20 40\n",
    "\n",
    "          * - Key\n",
    "            - Value\n",
    "{%- for k, v in p.valmap.items() %}\n",
    "          * - {{ k }}\n",
    "            - {{ v }}\n",
    "{%- endfor %}\n",
    "       {%- else %} N/A {%- endif %}\n",
    "{%- endfor %}\n",
    "\n",
    "**Description**: {{ cmd.description or '' }}\n",
    "''')\n",
    "\n",
    "def group_key(cmd_str):\n",
    "    m = re.match(r'^AT\\+([A-Z]+)', (cmd_str or \"\").upper())\n",
    "    if not m: return \"AT-OTHER\"\n",
    "    token = m.group(1)\n",
    "    return f\"AT-{token[:2]}\" if len(token) >= 2 else \"AT-OTHER\"\n",
    "\n",
    "def yaml_to_rst(yaml_path, rst_dir):\n",
    "    with open(yaml_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    cmds = data.get(\"commands\", [])\n",
    "\n",
    "    groups = defaultdict(list)\n",
    "    for cmd in cmds:\n",
    "        rst_text = PAGE_TMPL.render(cmd=cmd)\n",
    "        fname = f\"{cmd['command']}.rst\"\n",
    "        with open(os.path.join(rst_dir, fname), \"w\", encoding=\"utf-8\") as fo:\n",
    "            fo.write(rst_text)\n",
    "        groups[group_key(cmd[\"command\"])].append(cmd[\"command\"])\n",
    "\n",
    "    index_lines = [\"AT Manual\", \"=========\", \"\", \".. toctree::\", \"   :maxdepth: 1\", \"\"]\n",
    "    for g in sorted(groups.keys()):\n",
    "        grp_name = f\"index_{g}.rst\"\n",
    "        index_lines.append(f\"   {grp_name[:-4]}\")\n",
    "        glines = [g, \"=\" * len(g), \"\", \".. toctree::\", \"   :maxdepth: 1\", \"\"]\n",
    "        for c in groups[g]:\n",
    "            glines.append(f\"   {c}\")\n",
    "        with open(os.path.join(rst_dir, grp_name), \"w\", encoding=\"utf-8\") as fo:\n",
    "            fo.write(\"\\n\".join(glines))\n",
    "\n",
    "    with open(os.path.join(rst_dir, \"index.rst\"), \"w\", encoding=\"utf-8\") as fo:\n",
    "        fo.write(\"\\n\".join(index_lines))\n",
    "\n",
    "    print(f\"✅ RST 已生成到 {rst_dir}（含分组索引）\")\n",
    "\n",
    "yaml_to_rst(YAML_OUT, RST_DIR)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 — 清理并初始化 Sphinx（防止旧构建污染）"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if os.path.exists(DOCS_DIR):\n",
    "    print(\"⚠️ 检测到旧 docs/，正在清理...\")\n",
    "    shutil.rmtree(DOCS_DIR)\n",
    "    print(\"✅ 已删除旧 docs/\")\n",
    "\n",
    "!sphinx-quickstart {DOCS_DIR} --sep --project \"AT Command Manual\" --author \"Doc Team\" --release \"1.0\" -q\n",
    "\n",
    "conf_py = os.path.join(DOCS_DIR, \"source\", \"conf.py\")\n",
    "with open(conf_py, \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write('\\nhtml_theme = \"sphinx_rtd_theme\"\\n')\n",
    "\n",
    "shutil.copytree(RST_DIR, os.path.join(DOCS_DIR, \"source\"), dirs_exist_ok=True)\n",
    "print(\"✅ Sphinx 初始化完成并复制 RST\")\n",
    "print_tree(\"docs\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 — 构建 HTML（失败自动回退 docutils 版本）"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "SRC_DIR = os.path.join(DOCS_DIR, \"source\")\n",
    "BUILD_DIR = os.path.join(DOCS_DIR, \"build\", \"html\")\n",
    "os.makedirs(BUILD_DIR, exist_ok=True)\n",
    "\n",
    "def build_html_with_fallback():\n",
    "    print(\"📦 开始构建 HTML ...\")\n",
    "    cmd = [sys.executable, \"-m\", \"sphinx\", \"-b\", \"html\", SRC_DIR, BUILD_DIR]\n",
    "    p = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    print(p.stdout); print(p.stderr)\n",
    "    if p.returncode == 0 and os.path.exists(os.path.join(BUILD_DIR, \"index.html\")):\n",
    "        print(\"✅ HTML 构建成功 → docs/build/html/index.html\")\n",
    "        return True\n",
    "\n",
    "    print(\"❌ 初次构建失败，尝试回退 docutils 并重试 ...\")\n",
    "    _ = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"docutils<0.21\"])\n",
    "    p2 = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    print(p2.stdout); print(p2.stderr)\n",
    "    if p2.returncode == 0 and os.path.exists(os.path.join(BUILD_DIR, \"index.html\")):\n",
    "        print(\"✅ 回退后构建成功 → docs/build/html/index.html\")\n",
    "        return True\n",
    "\n",
    "    print(\"❌ 构建失败，请检查上面的日志输出。\")\n",
    "    return False\n",
    "\n",
    "build_html_with_fallback()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🟢 Step 6 — 一键执行 `run_all(clean=True)`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def run_all(clean=True):\n",
    "    _ = extract_word_to_csv(IN_WORD, CSV_OUT)\n",
    "    csv_to_yaml(CSV_OUT, YAML_OUT)\n",
    "    yaml_to_rst(YAML_OUT, RST_DIR)\n",
    "    if clean and os.path.exists(DOCS_DIR):\n",
    "        print(\"⚠️ run_all: 清理旧 docs/ ...\")\n",
    "        shutil.rmtree(DOCS_DIR)\n",
    "    get_ipython().system('sphinx-quickstart docs --sep --project \"AT Command Manual\" --author \"Doc Team\" --release \"1.0\" -q')\n",
    "    with open(os.path.join(DOCS_DIR, \"source\", \"conf.py\"), \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write('\\nhtml_theme = \"sphinx_rtd_theme\"\\n')\n",
    "    shutil.copytree(RST_DIR, os.path.join(DOCS_DIR, \"source\"), dirs_exist_ok=True)\n",
    "    build_html_with_fallback()\n",
    "    print(\"\\n✅ 全流程完成。HTML 查看：docs/build/html/index.html\")\n",
    "    print(\"📝 解析日志：parse_log.txt\")\n",
    "\n",
    "print(\"准备就绪。按顺序运行各 Step，或直接 run_all(clean=True)。\")"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
